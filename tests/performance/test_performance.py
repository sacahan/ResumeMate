#!/usr/bin/env python3
"""ResumeMate æ•ˆèƒ½æ¸¬è©¦è…³æœ¬"""

import asyncio
import time
import statistics
import sys
import os

sys.path.append(os.path.join(os.path.dirname(__file__), "..", "..", "src"))

from backend.models import Question
from backend.processor import ResumeMateProcessor


async def measure_response_time(processor, question_text):
    """æ¸¬é‡å–®ä¸€å•é¡Œçš„å›æ‡‰æ™‚é–“"""
    start_time = time.time()

    question = Question(text=question_text)
    response = await processor.process_question(question)

    end_time = time.time()
    response_time = end_time - start_time

    return {
        "question": question_text,
        "response_time": response_time,
        "answer_length": len(response.answer),
        "confidence": response.confidence,
        "sources_count": len(response.sources),
    }


async def run_performance_tests():
    """åŸ·è¡Œæ•ˆèƒ½æ¸¬è©¦"""
    print("ğŸš€ ResumeMate æ•ˆèƒ½æ¸¬è©¦é–‹å§‹")
    print("=" * 60)

    # åˆå§‹åŒ–è™•ç†å™¨
    print("æ­£åœ¨åˆå§‹åŒ–è™•ç†å™¨...")
    processor = ResumeMateProcessor()

    # æ¸¬è©¦å•é¡Œé›†
    test_questions = [
        "ä»‹ç´¹ä¸€ä¸‹è‡ªå·±",
        "ä½ æœ‰ä»€éº¼æŠ€èƒ½ï¼Ÿ",
        "ä½ çš„å·¥ä½œç¶“é©—å¦‚ä½•ï¼Ÿ",
        "å‘Šè¨´æˆ‘ä½ çš„å°ˆæ¡ˆç¶“æ­·",
        "ä½ æœƒä»€éº¼ç¨‹å¼èªè¨€ï¼Ÿ",
        "å¦‚ä½•è¯çµ¡ä½ ï¼Ÿ",
        "ä½ çš„æ•™è‚²èƒŒæ™¯æ˜¯ä»€éº¼ï¼Ÿ",
        "ä½ æœ‰ä»€éº¼å°ˆæ¥­èƒ½åŠ›ï¼Ÿ",
        "æè¿°ä¸€ä¸‹ä½ çš„è·æ¥­è¦åŠƒ",
        "ä½ æœ€æ“…é•·ä»€éº¼æŠ€è¡“ï¼Ÿ",
    ]

    print(f"æ¸¬è©¦å•é¡Œæ•¸é‡: {len(test_questions)}")
    print("é–‹å§‹æ¸¬è©¦...\n")

    # åŸ·è¡Œæ¸¬è©¦
    results = []
    for i, question in enumerate(test_questions, 1):
        print(f"[{i}/{len(test_questions)}] æ¸¬è©¦: {question}")

        try:
            result = await measure_response_time(processor, question)
            results.append(result)

            print(f"  â±ï¸  å›æ‡‰æ™‚é–“: {result['response_time']:.2f}s")
            print(f"  ğŸ“ å›ç­”é•·åº¦: {result['answer_length']} å­—å…ƒ")
            print(f"  ğŸ¯ ä¿¡å¿ƒåˆ†æ•¸: {result['confidence']:.3f}")
            print(f"  ğŸ“š ä¾†æºæ•¸é‡: {result['sources_count']}")
            print()

        except Exception as e:
            print(f"  âŒ æ¸¬è©¦å¤±æ•—: {e}")
            print()
            continue

    # çµ±è¨ˆåˆ†æ
    if results:
        response_times = [r["response_time"] for r in results]
        answer_lengths = [r["answer_length"] for r in results]
        confidences = [r["confidence"] for r in results]

        print("\nğŸ“Š æ•ˆèƒ½çµ±è¨ˆå ±å‘Š")
        print("=" * 60)
        print(f"æˆåŠŸæ¸¬è©¦æ•¸é‡: {len(results)}/{len(test_questions)}")
        print(f"æˆåŠŸç‡: {len(results)/len(test_questions)*100:.1f}%")
        print("\nâ±ï¸  å›æ‡‰æ™‚é–“çµ±è¨ˆ:")
        print(f"  å¹³å‡: {statistics.mean(response_times):.2f}s")
        print(f"  ä¸­ä½æ•¸: {statistics.median(response_times):.2f}s")
        print(f"  æœ€çŸ­: {min(response_times):.2f}s")
        print(f"  æœ€é•·: {max(response_times):.2f}s")
        print(f"  æ¨™æº–å·®: {statistics.stdev(response_times):.2f}s")

        print("\nğŸ“ å›ç­”å“è³ªçµ±è¨ˆ:")
        print(f"  å¹³å‡å›ç­”é•·åº¦: {statistics.mean(answer_lengths):.0f} å­—å…ƒ")
        print(f"  å¹³å‡ä¿¡å¿ƒåˆ†æ•¸: {statistics.mean(confidences):.3f}")

        # æ•ˆèƒ½åˆ†ç´š
        avg_time = statistics.mean(response_times)
        if avg_time < 3.0:
            grade = "ğŸ† å„ªç§€"
        elif avg_time < 5.0:
            grade = "âœ… è‰¯å¥½"
        elif avg_time < 8.0:
            grade = "âš ï¸ æ™®é€š"
        else:
            grade = "âŒ éœ€è¦æ”¹å–„"

        print(f"\nğŸ¯ æ•´é«”æ•ˆèƒ½è©•ç´š: {grade}")
        print(f"   å¹³å‡å›æ‡‰æ™‚é–“: {avg_time:.2f}s")

        # æª¢æŸ¥æ˜¯å¦æœ‰ç•°å¸¸æ…¢çš„å›æ‡‰
        slow_threshold = avg_time + 2 * statistics.stdev(response_times)
        slow_queries = [r for r in results if r["response_time"] > slow_threshold]

        if slow_queries:
            print(f"\nâš ï¸  ç•°å¸¸æ…¢å›æ‡‰ (>{slow_threshold:.2f}s):")
            for query in slow_queries:
                print(f"  - {query['question']}: {query['response_time']:.2f}s")

    print("\nâœ… æ•ˆèƒ½æ¸¬è©¦å®Œæˆ")


if __name__ == "__main__":
    asyncio.run(run_performance_tests())
