# .env.example
# 範例環境變數檔案 (不要把真正的金鑰提交到版本控制)
# 將本檔複製為 .env 並填入您的金鑰與設定：
#   cp .env.example .env

# ═══════════════════════════════════════════════════════════════
# 🤖 LLM 模型配置 (Agent 使用)
# ═══════════════════════════════════════════════════════════════

# GitHub Copilot (推薦)
# 使用 LiteLLM 與 GitHub Copilot 模型
# GITHUB_COPILOT_TOKEN 是可選的：
#   - 若不設定，首次使用會提示 OAuth Device Flow 認證
#   - 若設定，會直接使用該 Token (CI/CD 場景)
# GITHUB_COPILOT_TOKEN="ghp_xxxxxxxxxxxxx"

# Agent 使用的模型
# 當使用 GitHub Copilot 時的可選值：
#   - gpt-5 (高能力通用模型，回應較慢)
#   - gpt-5-mini (快速輕量級模型，推薦用於一般任務)
AGENT_MODEL="gpt-4o"

# LLM 回覆長度控制
# 可選值：brief (簡潔 1-2 句), normal (標準 2-4 句), detailed (詳細 3-5 段)
AGENT_RESPONSE_LENGTH="normal"

# 品質檢核設定 (評估 Agent 使用)
# 是否啟用進階品質分析
ENABLE_QUALITY_CHECK="true"
# 品質評分閾值 (0.0-1.0)，低於此值會升級人工處理
QUALITY_THRESHOLD="0.75"

# ═══════════════════════════════════════════════════════════════
# OpenAI (可選，當不使用 GitHub Copilot 時)
# ═══════════════════════════════════════════════════════════════
# 若使用 OpenAI 官方 API，請設定 OPENAI_API_KEY
# 若使用 Azure OpenAI，請同時設定 OPENAI_API_BASE, OPENAI_API_TYPE=azure, OPENAI_API_VERSION
OPENAI_API_KEY="your-openai-api-key-here"

# 🎯 嵌入模型設定 (向量化)
# 向量化提供者選擇：
#   - local: 使用本地模型 (推薦) - 快速、免費、隱私保護
#   - openai: 使用 OpenAI API - 需要 API 金鑰和網路連接
EMBEDDING_PROVIDER="local"

# OpenAI 嵌入模型 (當 EMBEDDING_PROVIDER=openai 時使用)
# 支援模型： text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002
EMBEDDING_MODEL="text-embedding-3-small"

# 本地嵌入模型 (當 EMBEDDING_PROVIDER=local 時使用)
# 推薦模型：
#   - all-MiniLM-L6-v2: 輕量快速，多語言支援 (23MB)
#   - BAAI/bge-small-zh-v1.5: 中文優化 (102MB)
#   - moka-ai/m3e-small: 中文語義強化 (93MB)
LOCAL_MODEL_NAME="all-MiniLM-L6-v2"

# 計算設備選擇：
#   - cpu: CPU 計算 (相容性最佳)
#   - cuda: NVIDIA GPU 加速 (需要 CUDA)
#   - mps: Apple Silicon GPU 加速 (M1/M2/M3 Mac)
DEVICE="cpu"

BATCH_SIZE=100
CHROMA_DB_PATH="./chroma_db"

# ChromaDB Collection 名稱 (自動選擇規則)
# 留空則根據模型自動選擇：
#   - text-embedding-3-small → "markdown_documents_openai"
#   - all-MiniLM-L6-v2 → "markdown_documents_minilm"
#   - BGE 系列 → "markdown_documents_bge"
#   - M3E 系列 → "markdown_documents_m3e"
# 或手動指定 collection 名稱覆蓋自動選擇
CHROMA_COLLECTION_NAME=""

# Hugging Face (用於部署/上傳 Spaces 等，可選)
HF_TOKEN="your-hf-token-here"
HF_SPACE_NAME="resumemate-chat" # 預設 space 名稱

# ChromaDB (本專案預設使用本機的 chroma 資料夾)
# 如果需要自訂路徑，可設定 CHROMA_DB_PATH
CHROMA_DB_PATH="your-custom-chroma-db-path"

# Gradio / 服務設定
GRADIO_SERVER_NAME="0.0.0.0"
GRADIO_SERVER_PORT=7860
# 啟用 Gradio 共享模式，生成公開 URL 供外部訪問
# 可選值：true (啟用共享), false (禁用共享)
# - true: 生成臨時公開 URL (例如 https://xxxxx.gradio.live)，任何人可訪問
# - false: 僅在本地網絡訪問，更安全但需要配置網絡
GRADIO_SHARE="false"

# 日誌與環境
ENVIRONMENT="development"
LOG_LEVEL="INFO"

# 🔧 本地向量化性能建議：
# 1. 使用 EMBEDDING_PROVIDER="local" 可獲得 10-25倍 速度提升
# 2. Apple Silicon Mac 建議設定 DEVICE="mps" 以啟用 GPU 加速
# 3. NVIDIA GPU 用戶建議設定 DEVICE="cuda" 以啟用 GPU 加速
# 4. 本地模型首次載入需下載，之後完全離線運行

# 安全提醒：
# - 不要在公開倉庫提交含有實際金鑰的 .env 檔案
# - 使用 CI / secret manager 保存生產環境金鑰
# - 本地模型模式下可選擇不設定 OPENAI_API_KEY (僅查詢向量化)
