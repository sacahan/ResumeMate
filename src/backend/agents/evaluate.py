"""Evaluate Agent å¯¦ä½œ

ä½¿ç”¨ OpenAI Agents SDK æ¨™æº–å¯¦ç¾å›ç­”è©•ä¼°èˆ‡å“è³ªæ§åˆ¶åŠŸèƒ½ã€‚
"""

from __future__ import annotations

import os
import json
from dotenv import load_dotenv
import logging
from typing import List, Dict, Literal, Any, Optional
from pydantic import BaseModel, Field, ConfigDict

# ç¢ºä¿ Runner å·²æ­£ç¢ºå¼•å…¥
from agents import Agent, Runner, AgentOutputSchema, ModelSettings
from backend.models import (
    AnalysisResult,
    EvaluationResult,
    AgentDecision,
)

load_dotenv(override=True)

logger = logging.getLogger(__name__)


DEFAULT_INSTRUCTIONS = """# éŸ“ä¸–ç¿” AI å±¥æ­·åŠ©ç† - å“è³ªè©•ä¼°ä»£ç†

## æ ¸å¿ƒè·è²¬
ä½ æ˜¯éŸ“ä¸–ç¿”çš„ AI å“è³ªè©•ä¼°åŠ©ç†ï¼Œè² è²¬å¯©æŸ¥åˆ†æä»£ç†çš„è¼¸å‡ºçµæœï¼Œç¢ºä¿æä¾›çµ¦ç”¨æˆ¶çš„æœ€çµ‚å›ç­”é”åˆ°å°ˆæ¥­æ¨™æº–ã€‚ä½ ä»£è¡¨éŸ“ä¸–ç¿”æœ¬äººé€²è¡Œæœ€å¾Œçš„å“è³ªæŠŠé—œï¼Œç¶­è­·ä»–çš„å°ˆæ¥­å½¢è±¡ã€‚

## ğŸ¯ è©•ä¼°ä½¿å‘½
1. **å“è³ªé©—è­‰**ï¼šç¢ºä¿å›ç­”æº–ç¢ºã€ç›¸é—œä¸”æœ‰åƒ¹å€¼
2. **èªæ°£èª¿æ ¡**ï¼šç¶­æŒéŸ“ä¸–ç¿”å°ˆæ¥­è¦ªå’Œçš„å€‹äººé¢¨æ ¼
3. **æ±ºç­–æ™ºæ…§**ï¼šåˆ¤æ–·å›ç­”æ˜¯å¦éœ€è¦æ¾„æ¸…æˆ–å‡ç´šäººå·¥è™•ç†
4. **ç”¨æˆ¶é«”é©—**ï¼šæä¾›å°æ‹›å‹Ÿæ–¹å’Œåˆä½œå¤¥ä¼´æœ‰å¯¦ç”¨åƒ¹å€¼çš„å›ç­”

## ğŸ’¬ èªæ°£èˆ‡å€‹æ€§æ¨™æº–

### âœ… è‡ªç„¶è¡¨é”åŸå‰‡
- **ç¬¬ä¸€äººç¨±è‡ªç„¶åŒ–**ï¼šå¦‚éŸ“ä¸–ç¿”è¦ªè‡ªå›ç­”ï¼Œèªå¥æµæš¢è‡ªç„¶
- **é¿å…å®¢è§€æè¿°**ï¼šæ‹’çµ•ã€Œæ ¹æ“šå±¥æ­·ã€ã€ã€Œè³‡æ–™é¡¯ç¤ºã€ç­‰ç”Ÿç¡¬ç”¨è©
- **å€‹äººåŒ–è¡¨é”**ï¼šä½¿ç”¨ã€Œæˆ‘åœ¨...ã€ã€ã€Œæˆ‘çš„å°ˆé•·æ˜¯...ã€ã€ã€Œæˆ‘æ“…é•·...ã€
- **é©åº¦åˆ†äº«è§€é»**ï¼šåŠ å…¥å€‹äººç¶“é©—æ„Ÿæ‚Ÿï¼Œå¢åŠ çœŸå¯¦æ„Ÿ
- **æ­£é«”ä¸­æ–‡**ï¼šç¢ºä¿ä½¿ç”¨ zh_TW ç¹é«”å­—ç¬¦

### ğŸŒŸ å€‹æ€§ç‰¹è³ªå±•ç¾
- **æŠ€è¡“ç†±å¿±**ï¼šå°æ–°æŠ€è¡“ä¿æŒç©æ¥µå­¸ç¿’æ…‹åº¦
- **å°ˆæ¥­è‡ªä¿¡**ï¼šå±•ç¾æŠ€è¡“å¯¦åŠ›ä½†ä¸é©•å‚²
- **åœ˜éšŠç²¾ç¥**ï¼šå¼·èª¿å”ä½œèˆ‡æºé€šèƒ½åŠ›
- **è§£æ±ºå°å‘**ï¼šå°ˆæ³¨æ–¼å¯¦éš›å•é¡Œè§£æ±º

## ğŸ” æ™ºæ…§æ±ºç­–æµç¨‹

### æ±ºç­–å„ªå…ˆç´š (ç”±é«˜åˆ°ä½)

#### 1. ğŸ† è¯çµ¡è³‡è¨ŠæŸ¥è©¢ [è‡ªå‹•é€šé]
**è§¸ç™¼æ¢ä»¶** (ä»»ä¸€æ»¿è¶³å³å¯):
- `used_contact_info_tool = true`
- `question_type = "contact"` ä¸” `confidence > 0.8`
- `metadata.source = "get_contact_info"`

**è™•ç†æ–¹å¼**: `status = "ok"`ï¼Œç›´æ¥æä¾›è¯çµ¡è³‡è¨Š

#### 2. ğŸš« å®Œå…¨è¶…å‡ºç¯„åœ
**è§¸ç™¼æ¢ä»¶**:
- èˆ‡è·æ¥­ç”Ÿæ¶¯å®Œå…¨ç„¡é—œçš„å•é¡Œ (å¤©æ°£ã€å¨›æ¨‚å…«å¦ã€çƒ¹é£ªé£Ÿè­œã€é«”è‚²è³½äº‹ç­‰)
- âš ï¸ **é‡è¦**ï¼šä»¥ä¸‹å±¬æ–¼æ­£å¸¸ç¯„åœï¼Œä¸æ‡‰æ­¸é¡ç‚ºè¶…å‡ºç¯„åœ
  * è‡ªæˆ‘ä»‹ç´¹ã€å€‹äººèƒŒæ™¯ã€å·¥ä½œç¶“é©—
  * æŠ€èƒ½ã€æ•™è‚²ã€å°ˆæ¡ˆç¶“é©—
  * è·æ¥­è¦åŠƒã€å·¥ä½œç†å¿µ
  * åœ˜éšŠåˆä½œã€é ˜å°ç¶“é©—

**è™•ç†æ–¹å¼**: `status = "out_of_scope"`

#### 3. ğŸ”’ çœŸæ­£æ•æ„Ÿè³‡è¨Š
**è§¸ç™¼æ¢ä»¶**:
- è–ªè³‡ã€å…§éƒ¨æ©Ÿå¯†ã€å®¶åº­éš±ç§ç­‰
- âš ï¸ æ³¨æ„ï¼šæ¨™æº–å±¥æ­·è³‡è¨Šä¸å±¬æ•æ„Ÿ (å±…ä½åœ°ã€å·¥ä½œå€åŸŸã€è¯çµ¡æ–¹å¼ã€æ•™è‚²èƒŒæ™¯ã€æŠ€èƒ½ç¶“é©—ç­‰)

**è™•ç†æ–¹å¼**: `status = "escalate_to_human"`

#### 4. ğŸ“Š ä¿¡å¿ƒåº¦éä½
**è§¸ç™¼æ¢ä»¶**:
- `analysis_confidence < 0.4`
- `sources` ç‚ºç©ºæˆ–ä¸è¶³

**è™•ç†æ–¹å¼**: `status = "escalate_to_human"`

#### 5. â“ éœ€è¦æ¾„æ¸…
**è§¸ç™¼æ¢ä»¶**:
- `confidence âˆˆ [0.4, 0.7)` ä¸”æ¶‰åŠé‡è¦æŠ€è¡“/ç¶“é©—
- å•é¡Œæ¨¡ç³Šï¼Œå¯é€šéè£œå……å…·é«”è³‡è¨Šè§£æ±º

**è™•ç†æ–¹å¼**: `status = "needs_clarification"`ï¼Œæä¾›ç²¾æº–è¿½å•æ¸…å–®

#### 6. âœ… å“è³ªåˆæ ¼
**è§¸ç™¼æ¢ä»¶**:
- `confidence â‰¥ 0.7` ä¸”æœ‰å¯ä¿¡ä¾†æºæ”¯æŒ
- è‰ç¨¿å…§å®¹å®Œæ•´ã€æº–ç¢ºã€ç¬¦åˆéŸ“ä¸–ç¿”èªæ°£

**è™•ç†æ–¹å¼**: `status = "ok"`ï¼Œå¯èƒ½éœ€è¦èªæ°£æ½¤é£¾

#### 7. âœï¸ éœ€è¦ç·¨è¼¯
**è§¸ç™¼æ¢ä»¶**:
- å…§å®¹åŸºæœ¬æ­£ç¢ºä½†èªæ°£ä¸è‡ªç„¶
- å°å¹…èª¿æ•´å³å¯é”åˆ°ç™¼å¸ƒæ¨™æº–

**è™•ç†æ–¹å¼**: `status = "needs_edit"`ï¼Œæä¾›å…·é«”ä¿®æ”¹å»ºè­°

#### 8. ğŸ†˜ å…¶ä»–æƒ…æ³
**è™•ç†æ–¹å¼**: å‚¾å‘ `status = "escalate_to_human"`ï¼Œç¢ºä¿å“è³ª

## ğŸ“ å“è³ªè©•ä¼°æ¨™æº–

### ğŸ¯ å…§å®¹å“è³ªæª¢æ ¸
1. **äº‹å¯¦æº–ç¢ºæ€§**: åŸºæ–¼æª¢ç´¢çµæœï¼Œä¸å¯è™›æ§‹
2. **ä¾†æºè¦†è“‹åº¦**: è‡³å°‘1å€‹å¯ä¿¡ä¾†æºæ”¯æŒä¸»è¦è«–é»
3. **è³‡è¨Šä¸€è‡´æ€§**: ä¾†æºé–“ç„¡çŸ›ç›¾ï¼Œé‚è¼¯æ¸…æ™°
4. **å°ˆæ¥­æ·±åº¦**: æŠ€è¡“å•é¡Œå±•ç¾é©ç•¶å°ˆæ¥­çŸ¥è­˜
5. **å¯¦ç”¨åƒ¹å€¼**: å°æ‹›å‹Ÿæ–¹/åˆä½œå¤¥ä¼´æœ‰åƒè€ƒåƒ¹å€¼

### ğŸ¨ èªæ°£é¢¨æ ¼è©•ä¼°
1. **è‡ªç„¶æµæš¢**: å¦‚çœŸäººå°è©±èˆ¬è‡ªç„¶
2. **å€‹æ€§ä¸€è‡´**: ç¬¦åˆéŸ“ä¸–ç¿”çš„å°ˆæ¥­å½¢è±¡
3. **é©åº¦è¦ªåˆ‡**: å°ˆæ¥­ä¸­å¸¶æœ‰æº«åº¦
4. **ç”¨è©ç²¾æº–**: æŠ€è¡“ç”¨è©æº–ç¢ºï¼Œè¡¨é”æ¸…æ™°

### ğŸšï¸ ä¿¡å¿ƒåº¦èª¿æ•´åŸå‰‡
- **è¯çµ¡è³‡è¨Š**: å›ºå®š `confidence = 1.0`
- **ç²¾ç¢ºåŒ¹é…**: `confidence âˆˆ [0.8, 1.0]`
- **éƒ¨åˆ†åŒ¹é…**: `confidence âˆˆ [0.5, 0.8]`
- **ç›¸é—œä½†ä¸ç¢ºå®š**: `confidence âˆˆ [0.2, 0.5]`
- **ä¸ç›¸é—œ/éŒ¯èª¤**: `confidence âˆˆ [0.0, 0.2]`

## ğŸ“¤ è¼¸å‡ºæ ¼å¼è¦ç¯„

### ğŸ”§ JSON çµæ§‹ (åƒ…é™ä»¥ä¸‹5å€‹æ¬„ä½)
```json
{
  "final_answer": "ç¬¬ä¸€äººç¨±è‡ªç„¶å›ç­”",
  "sources": ["document_id_1", "document_id_2"],
  "confidence": 0.85,
  "status": "ok|needs_edit|needs_clarification|out_of_scope|escalate_to_human",
  "metadata": {
    "reason": "æ±ºç­–åŸå› èªªæ˜",
    "missing_fields": ["ç¼ºå°‘çš„é—œéµè³‡è¨Š"],
    "original_question": "åŸå§‹å•é¡Œ",
    "analysis_confidence": 0.75
  }
}
```

### âš ï¸ åš´æ ¼é™åˆ¶
- åƒ…è¼¸å‡ºä¸Šè¿°5å€‹æ¬„ä½ï¼Œç¦æ­¢å…¶ä»–å…§å®¹
- ç¦æ­¢åŒ…å« schema ç›¸é—œæ¬„ä½
- ç¦æ­¢è¼¸å‡ºé¡å¤–èªªæ˜æ–‡å­—

## ğŸ­ å›ç­”ç¯„ä¾‹

### âœ… å„ªè³ªå›ç­”ç¯„ä¾‹

**è¯çµ¡è³‡è¨ŠæŸ¥è©¢**:
```
å•é¡Œ: "å¦‚ä½•èˆ‡ä½ è¯çµ¡ï¼Ÿ"
å›ç­”: "ä½ å¯ä»¥é€é sacahan@gmail.com èˆ‡æˆ‘è¯çµ¡ï¼Œæˆ‘æœƒç›¡å¿«å›å¾©ä½ çš„è¨Šæ¯ã€‚"
status: "ok", confidence: 1.0
```

**æŠ€è¡“èƒ½åŠ›æŸ¥è©¢**:
```
å•é¡Œ: "ä½ åœ¨ AI é ˜åŸŸæœ‰ä»€éº¼ç¶“é©—ï¼Ÿ"
å›ç­”: "æˆ‘åœ¨ AI/ML é ˜åŸŸæœ‰è¶…é5å¹´çš„å¯¦å‹™ç¶“é©—ï¼Œå°ˆç²¾æ–¼æ©Ÿå™¨å­¸ç¿’æ¨¡å‹é–‹ç™¼å’Œæ·±åº¦å­¸ç¿’æ‡‰ç”¨ï¼Œæ›¾ä¸»å°å¤šå€‹æˆåŠŸçš„ AI å°ˆæ¡ˆè½åœ°ã€‚"
status: "ok", confidence: 0.9
```

**éœ€è¦æ¾„æ¸…ç¯„ä¾‹**:
```
å•é¡Œ: "ä½ çš„å°ˆæ¡ˆç¶“é©—å¦‚ä½•ï¼Ÿ"
å›ç­”: "æˆ‘æƒ³æ›´å…·é«”åœ°å›ç­”ä½ çš„å•é¡Œã€‚ä½ å¸Œæœ›äº†è§£å“ªå€‹é ˜åŸŸçš„å°ˆæ¡ˆç¶“é©—å‘¢ï¼Ÿæ¯”å¦‚ AI/ML å°ˆæ¡ˆã€ç³»çµ±æ¶æ§‹è¨­è¨ˆï¼Œé‚„æ˜¯åœ˜éšŠç®¡ç†ç¶“é©—ï¼Ÿ"
status: "needs_clarification"
```

### ğŸ†˜ å‡ç´šäººå·¥è™•ç†è©±è¡“
ç•¶ `status = "escalate_to_human"` æ™‚ï¼Œçµ±ä¸€ä½¿ç”¨:

```
"ç”±æ–¼ç›®å‰å¯æŸ¥åˆ°çš„è³‡æ–™ç„¡æ³•ä¿è­‰ç­”æ¡ˆæ­£ç¢ºæ€§ã€‚æ˜¯å¦åŒæ„æˆ‘å…ˆè¨˜éŒ„ä¸‹å•é¡Œï¼Œå†ç”±æœ¬äººé€²è¡Œå›è¦†ï¼Ÿéº»ç…©å†æä¾›è¯çµ¡æ–¹å¼ï¼ˆç¨±å‘¼/Email/é›»è©±/Lineï¼‰ã€‚"
```

## ğŸš€ ä½¿å‘½æé†’
è¨˜ä½ï¼Œä½ ä»£è¡¨éŸ“ä¸–ç¿”çš„å°ˆæ¥­å½¢è±¡ã€‚æ¯å€‹å›ç­”éƒ½è¦:
- å±•ç¾ä»–çš„æŠ€è¡“å¯¦åŠ›å’Œè§£æ±ºå•é¡Œçš„èƒ½åŠ›
- é«”ç¾ä»–çš„å­¸ç¿’ç†±å¿±å’Œåœ˜éšŠç²¾ç¥
- ç‚ºç”¨æˆ¶æä¾›çœŸæ­£æœ‰åƒ¹å€¼çš„è³‡è¨Š
- ç¶­è­·è¦ªåˆ‡å°ˆæ¥­çš„å°è©±é«”é©—

è®“æ¯æ¬¡äº’å‹•éƒ½æˆç‚ºå±•ç¾éŸ“ä¸–ç¿”å„ªç§€å“è³ªçš„æ©Ÿæœƒï¼
"""

# ---------- JSON-safe type
JsonValue = Any


# å¯¬å®¹è¼¸å‡ºæ¨¡å‹ï¼ˆè‡ªå‹•å¿½ç•¥ LLM çš„é¡å¤–æ¬„ä½ï¼‰
class EvaluateOutput(BaseModel):
    model_config = ConfigDict(
        extra="ignore"
    )  # âœ… å¯¬å®¹ï¼šè‡ªå‹•å¿½ç•¥ LLM è¼¸å‡ºçš„é¡å¤–æ¬„ä½ï¼ˆå¦‚ descriptionï¼‰

    final_answer: str
    # æ”¹ç‚ºå­—ä¸²åˆ—è¡¨ä»¥ç¬¦åˆ Analysis Agent è¼¸å‡ºæ ¼å¼
    sources: List[str] = Field(default_factory=list)
    confidence: float = Field(ge=0.0, le=1.0)
    status: Literal[
        "ok",
        "needs_edit",
        "needs_clarification",
        "out_of_scope",
        "escalate_to_human",
    ]
    metadata: Dict[str, JsonValue] = Field(default_factory=dict)


class EvaluateAgent:
    """Evaluate Agent - å›ç­”è©•ä¼°èˆ‡å“è³ªæ§åˆ¶ä»£ç†äºº"""

    def __init__(self, llm: str = "gpt-4o-mini"):
        # å»ºç«‹ LiteLLM æ¨¡å‹
        self.llm_model, self.llm_settings = self._create_litellm_model_and_settings()
        self.response_length = os.environ.get("AGENT_RESPONSE_LENGTH", "normal")
        self.sdk_agent: Optional[Agent] = None

        self._initialize_sdk_agent()

    def _create_litellm_model_and_settings(self):
        """å‰µå»º OpenAI æ¨¡å‹å¯¦ä¾‹å’Œ ModelSettings

        Returns:
            Tuple[OpenAIChatCompletionsModel, ModelSettings]: (æ¨¡å‹å¯¦ä¾‹, è¨­ç½®)

        Note:
            ä½¿ç”¨ OpenAI SDK ç›´æ¥é€£æ¥ LiteLLM Proxyï¼Œé¿å… LiteLLM å…§éƒ¨çš„èªè­‰é‚è¼¯ã€‚
        """
        from openai import AsyncOpenAI
        from agents.models.openai_chatcompletions import OpenAIChatCompletionsModel

        # ä½¿ç”¨ LiteLLM Proxy é…ç½®
        api_key = os.getenv("LITELLM_PROXY_API_KEY")
        api_base = os.getenv("LITELLM_PROXY_API_BASE")
        proxy_model = os.getenv("LITELLM_PROXY_MODEL", "gpt-4o")

        if not api_key or not api_base:
            logger.error("âŒ æœªè¨­å®š LITELLM_PROXY ç›¸é—œç’°å¢ƒè®Šæ•¸")
            raise ValueError(
                "LITELLM_PROXY_API_KEY and LITELLM_PROXY_API_BASE are required"
            )

        logger.info(f"ğŸ“¡ ä½¿ç”¨ LiteLLM Proxy: {api_base}")
        logger.info(f"ğŸ“¡ Proxy Model: {proxy_model}")

        # å»ºç«‹ AsyncOpenAI client æŒ‡å‘ LiteLLM Proxy
        client = AsyncOpenAI(
            base_url=api_base,
            api_key=api_key,
        )

        # ä½¿ç”¨ OpenAIChatCompletionsModelï¼ˆç›¸å®¹é OpenAI å¾Œç«¯ï¼‰
        llm_model = OpenAIChatCompletionsModel(
            model=proxy_model,
            openai_client=client,
        )

        model_settings = ModelSettings(include_usage=True)

        logger.info(f"âœ… OpenAI æ¨¡å‹å·²å»ºç«‹: {proxy_model}")
        return llm_model, model_settings

    def _initialize_sdk_agent(self):
        """åˆå§‹åŒ– Evaluate Agent"""
        try:
            # æ ¹æ“šå›è¦†é•·åº¦è¨­å®šèª¿æ•´ instructions
            response_instructions = self._get_response_length_instructions()
            full_instructions = DEFAULT_INSTRUCTIONS + "\n\n" + response_instructions

            # å»ºç«‹åŸºç¤ ModelSettings
            base_settings = ModelSettings(
                max_completion_tokens=600,  # é©åº¦æ§åˆ¶å›ç­”é•·åº¦
            )

            # åˆä½µ GitHub Copilot çš„ extra_headers
            if self.llm_settings and self.llm_settings.extra_headers:
                base_settings.extra_headers = {
                    **(base_settings.extra_headers or {}),
                    **self.llm_settings.extra_headers,
                }

            # ğŸ” å“è³ªè©•ä¼°ä»£ç†é€²éšè¨­å®š
            # - åš´æ ¼è¼¸å‡ºæ ¼å¼ç¢ºä¿ä¸€è‡´æ€§
            # - ä½æº«åº¦åƒæ•¸æå‡æ±ºç­–ç©©å®šæ€§
            # - é©åº¦ token é™åˆ¶ç¶­æŒå›ç­”å“è³ª
            self.sdk_agent = Agent(
                name="éŸ“ä¸–ç¿”å“è³ªè©•ä¼°åŠ©ç†",
                instructions=full_instructions,
                model=self.llm_model,
                model_settings=base_settings,
                output_type=AgentOutputSchema(EvaluateOutput, strict_json_schema=False),
            )
            logger.info("ğŸ” éŸ“ä¸–ç¿”å“è³ªè©•ä¼°åŠ©ç†åˆå§‹åŒ–æˆåŠŸ")
            logger.info("âœ… å·²å•Ÿç”¨æ™ºæ…§å“è³ªæ§åˆ¶èˆ‡æ±ºç­–ç©©å®šæ©Ÿåˆ¶")

        except Exception as e:
            logger.error(f"åˆå§‹åŒ– Evaluate Agent å¤±æ•—: {e}")

    def _get_response_length_instructions(self) -> str:
        """æ ¹æ“šç’°å¢ƒè®Šæ•¸è¨­å®šå›å‚³å›è¦†é•·åº¦æ§åˆ¶æŒ‡ä»¤"""
        if self.response_length.lower() == "brief":
            return """## ğŸ“ å›è¦†é•·åº¦æ§åˆ¶ - ç°¡æ½”æ¨¡å¼
- **ç›®æ¨™é•·åº¦**: 1-2å¥è©±ï¼Œç›´æ“Šæ ¸å¿ƒ
- **å…§å®¹ç­–ç•¥**: åƒ…ä¿ç•™æœ€é—œéµè³‡è¨Šï¼Œå»é™¤èƒŒæ™¯æè¿°
- **èªæ°£èª¿æ•´**: ä¿æŒè¦ªåˆ‡ä½†æ›´åŠ ç›´æ¥æ˜ç¢º
- **é©ç”¨å ´æ™¯**: å¿«é€Ÿå•ç­”ã€åŸºç¤è³‡è¨Šç¢ºèª"""
        elif self.response_length.lower() == "detailed":
            return """## ğŸ“ å›è¦†é•·åº¦æ§åˆ¶ - è©³ç´°æ¨¡å¼
- **ç›®æ¨™é•·åº¦**: 3-5æ®µè½ï¼Œæä¾›å®Œæ•´è„ˆçµ¡
- **å…§å®¹ç­–ç•¥**: åŒ…å«èƒŒæ™¯è³‡è¨Šã€å…·é«”æ¡ˆä¾‹ã€å¯¦å‹™ç¶“é©—åˆ†äº«
- **èªæ°£èª¿æ•´**: å°ˆæ¥­æ·±å…¥ï¼Œå±•ç¾æŠ€è¡“æ€ç¶­èˆ‡è§£æ±ºå•é¡Œçš„éç¨‹
- **é©ç”¨å ´æ™¯**: æŠ€è¡“æ·±åº¦å•é¡Œã€å°ˆæ¡ˆç¶“é©—åˆ†äº«ã€è¤‡é›œæ¦‚å¿µè§£é‡‹"""
        else:  # normal
            return """## ğŸ“ å›è¦†é•·åº¦æ§åˆ¶ - æ¨™æº–æ¨¡å¼
- **ç›®æ¨™é•·åº¦**: 2-4å¥è©±ï¼Œå¹³è¡¡ç°¡æ½”èˆ‡å®Œæ•´æ€§
- **å…§å®¹ç­–ç•¥**: æ ¸å¿ƒè³‡è¨Š + é©åº¦èƒŒæ™¯ï¼Œä¿æŒè³‡è¨Šå¯†åº¦
- **èªæ°£èª¿æ•´**: è‡ªç„¶å°è©±ï¼Œå°ˆæ¥­è€Œè¦ªåˆ‡
- **é©ç”¨å ´æ™¯**: ä¸€èˆ¬å±¥æ­·å•é¡Œã€æŠ€èƒ½ç¶“é©—æŸ¥è©¢ã€æ—¥å¸¸äº’å‹•"""

    # -------------------------
    # å®‰å…¨è§£æï¼šå³ä½¿æ¨¡å‹å› schema/é›œè¨Šä¹Ÿèƒ½ä¿®å¾©
    # -------------------------
    def _safe_parse_output(self, result) -> Optional[EvaluateOutput]:
        """ç›¡åŠ›æŠŠ SDK è¼¸å‡ºè½‰æˆ EvaluateOutputï¼›å¤±æ•—å‰‡å› None

        ç”±æ–¼ä½¿ç”¨ extra="ignore"ï¼ŒPydantic æœƒè‡ªå‹•å¿½ç•¥é¡å¤–æ¬„ä½ï¼ˆå¦‚ descriptionï¼‰ï¼Œ
        æ‰€ä»¥ç„¡éœ€æ‰‹å‹•æ¸…æ´— schema ç›¸é—œæ¬„ä½ã€‚
        """
        try:
            # å˜—è©¦ SDK çš„ final_output_as
            return result.final_output_as(EvaluateOutput)
        except Exception as e:
            logger.warning(f"final_output_as å¤±æ•—ï¼Œå˜—è©¦æ‰‹å‹•è§£æï¼š{e}")

        # å‚™ç”¨æ–¹æ¡ˆï¼šæ‰‹å‹•è§£æ result.output
        raw = getattr(result, "output", None)
        if raw is None:
            logger.error("ç„¡æ³•å–å¾— result.output")
            return None

        try:
            if isinstance(raw, str):
                data = json.loads(raw)
            elif isinstance(raw, dict):
                data = raw
            else:
                logger.error(f"æœªçŸ¥è¼¸å‡ºå‹åˆ¥ï¼š{type(raw)}")
                return None

            # æŸäº›æ¨¡å‹æœƒå› schema-like çµæ§‹ï¼Œå˜—è©¦å¾ example è£œå€¼
            if "example" in data and isinstance(data["example"], dict):
                data = data["example"]

            # ä¿®æ­£å¸¸è¦‹çš„æ ¼å¼éŒ¯èª¤
            if "sources" in data and not isinstance(data["sources"], list):
                data["sources"] = (
                    [data["sources"]] if isinstance(data["sources"], str) else []
                )

            if "metadata" in data and data["metadata"] is None:
                data["metadata"] = {}

            if "confidence" in data and not isinstance(
                data["confidence"], (int, float)
            ):
                try:
                    data["confidence"] = float(data["confidence"])
                except (ValueError, TypeError):
                    data["confidence"] = 0.5

            # ç”±æ–¼ extra="ignore"ï¼Œé¡å¤–æ¬„ä½æœƒè¢«è‡ªå‹•å¿½ç•¥
            return EvaluateOutput.model_validate(data)
        except Exception as e:
            logger.error(f"æ‰‹å‹•è§£æè¼¸å‡ºå¤±æ•—ï¼š{e}")
            return None

    async def evaluate(self, analysis: AnalysisResult) -> EvaluationResult:
        """è©•ä¼°åˆ†æçµæœä¸¦ç”Ÿæˆæœ€çµ‚å›ç­”"""
        logger.info("é–‹å§‹è©•ä¼°åˆ†æçµæœ")

        try:
            return await self._evaluate_with_sdk(analysis)
        except Exception as e:
            logger.error(f"è©•ä¼°éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
            return EvaluationResult(
                final_answer="æŠ±æ­‰ï¼Œç³»çµ±è™•ç†æ‚¨çš„å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚",
                sources=[],
                confidence=0.0,
                status=self._fallback_status(),
                metadata={"error": str(e)},
            )

    def _fallback_status(self) -> AgentDecision:
        # å„ªå…ˆä½¿ç”¨ OUT_OF_SCOPEï¼Œå¦å‰‡å›å‚³ enum ç¬¬ä¸€å€‹å€¼
        if hasattr(AgentDecision, "OUT_OF_SCOPE"):
            return getattr(AgentDecision, "OUT_OF_SCOPE")
        try:
            return list(AgentDecision)[0]
        except Exception:
            # æ¥µç«¯ä¿åº•ï¼šå›å‚³å­—ä¸²ï¼ˆè‹¥æ¨¡å‹è¦æ±‚ enumï¼Œå¯åœ¨ä¸Šå±¤è½‰æ›ï¼‰
            return AgentDecision  # type: ignore

    def _map_status_to_agent_decision(self, status_str: str) -> AgentDecision:
        """å°‡è¼¸å‡ºç‹€æ…‹å­—ä¸²ç©©å¥æ˜ å°„åˆ° AgentDecision"""
        s = (status_str or "").strip().lower().replace("-", "_").replace(" ", "_")
        name_map = {
            "oos": "OUT_OF_SCOPE",
            "out_of_scope": "OUT_OF_SCOPE",
            "clarify": "CLARIFY",
            "needs_clarification": "CLARIFY",  # è‹¥æœ‰ NEEDS_CLARIFICATION ä¹Ÿæœƒåœ¨ä¸‹æ–¹å€™é¸å‘½ä¸­
            "ok": "RETRIEVE",  # è¡¨ç¤ºå¯ç›´æ¥ä½¿ç”¨ï¼›è‹¥æœ‰ OK ä¹Ÿæœƒè©¦åœ–å‘½ååŒ¹é…
            "needs_edit": "NEEDS_EDIT",
            "escalate_to_human": "ESCALATE_TO_HUMAN",
            "retrieve": "RETRIEVE",
        }
        candidates = [
            name_map.get(s),
            s.upper(),
        ]
        # ä¹Ÿå˜—è©¦æ›´å¸¸è¦‹åç¨±
        candidates.extend(
            [
                "OK",
                "NEEDS_EDIT",
                "NEEDS_CLARIFICATION",
                "OUT_OF_SCOPE",
                "ESCALATE_TO_HUMAN",
                "RETRIEVE",
                "CLARIFY",
            ]
        )
        for c in candidates:
            if not c:
                continue
            if hasattr(AgentDecision, c):
                return getattr(AgentDecision, c)
            # å˜—è©¦ä»¥ value è½‰æ›
            try:
                return AgentDecision(c)  # type: ignore
            except Exception:
                pass
        return self._fallback_status()

    async def _evaluate_with_sdk(self, analysis: AnalysisResult) -> EvaluationResult:
        """ä½¿ç”¨ OpenAI Agents SDK è©•ä¼°åˆ†æçµæœ"""
        # æª¢æŸ¥æ˜¯å¦ä½¿ç”¨äº† get_contact_info å·¥å…·
        used_contact_info_tool = False
        if analysis.metadata and isinstance(analysis.metadata, dict):
            # å¤šç¨®æ–¹å¼æª¢æŸ¥æ˜¯å¦ä½¿ç”¨äº†è¯çµ¡è³‡è¨Šå·¥å…·
            # 1. æª¢æŸ¥ metadata ä¸­çš„ source æ¬„ä½
            if analysis.metadata.get("source") == "get_contact_info":
                used_contact_info_tool = True
            # 2. æª¢æŸ¥ raw_output ä¸­æ˜¯å¦åŒ…å«å·¥å…·èª¿ç”¨
            raw_output = analysis.metadata.get("raw_output")
            if raw_output and isinstance(raw_output, str):
                if "get_contact_info" in raw_output:
                    used_contact_info_tool = True
            # 3. æª¢æŸ¥å•é¡Œé¡å‹æ˜¯å¦ç‚ºè¯çµ¡è³‡è¨Š
            if (
                getattr(analysis.question_type, "value", str(analysis.question_type))
                == "contact"
            ):
                # å°æ–¼è¯çµ¡è³‡è¨Šé¡å‹çš„å•é¡Œï¼Œå¦‚æœä¿¡å¿ƒåº¦é«˜ï¼Œä¹Ÿè¦–ç‚ºä½¿ç”¨äº†å·¥å…·
                if analysis.confidence > 0.8:
                    used_contact_info_tool = True

        # æº–å‚™ reviewer è¼¸å…¥ï¼šåŸå•é¡Œ + analysis å…¨é‡è¼¸å‡º
        analysis_data = {
            "original_question": getattr(analysis, "query", ""),
            "analysis_output": {
                "decision": getattr(analysis.decision, "value", str(analysis.decision)),
                "question_type": getattr(
                    analysis.question_type, "value", str(analysis.question_type)
                ),
                "confidence": analysis.confidence,
                "draft_answer": analysis.draft_answer or "",
                "metadata": analysis.metadata or {},
                "retrievals": [],
                "sources": [],  # è‹¥ analysis ç›´æ¥è¼¸å‡ºäº† sourcesï¼ˆæœ‰äº›ç®¡ç·šæœƒæœ‰ï¼‰
                "used_contact_info_tool": used_contact_info_tool,  # æ–°å¢æ¨™è¨˜
            },
        }

        # è½‰è¼‰æª¢ç´¢çµæœï¼ˆè‹¥æœ‰ï¼‰
        try:
            if analysis.retrievals:
                analysis_data["analysis_output"]["retrievals"] = [
                    {
                        "doc_id": getattr(r, "doc_id", getattr(r, "id", None)),
                        "score": getattr(r, "score", None),
                        "excerpt": getattr(r, "excerpt", None),
                        "metadata": getattr(r, "metadata", {}),
                    }
                    for r in analysis.retrievals[:5]
                ]
        except Exception as e:
            logger.warning(f"è½‰æ› retrievals å¤±æ•—ï¼š{e}")

        # è‹¥ analysis.metadata å…§æœ‰ sourcesï¼Œå¸¶å…¥
        try:
            meta_sources = (analysis.metadata or {}).get("sources", [])
            if isinstance(meta_sources, list):
                analysis_data["analysis_output"]["sources"] = meta_sources[:5]
        except Exception:
            pass

        # **é—œéµä¿®æ­£**ï¼šå°‡å­—å…¸è½‰æ›ç‚º JSON å­—ä¸²ï¼Œé€™æ˜¯ Runner.run() æœŸæœ›çš„æ ¼å¼
        input_text = json.dumps(analysis_data, ensure_ascii=False, indent=2)

        # åŸ·è¡Œ SDK Agent
        try:
            result = await Runner.run(self.sdk_agent, input=input_text)
            logger.info(f"Evaluate Agent å›è¦†: {result}")
        except Exception as e:
            logger.error(f"åŸ·è¡Œ Evaluate Agent æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return EvaluationResult(
                final_answer="æŠ±æ­‰ï¼Œè©•ä¼°æ‚¨çš„å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚",
                sources=[],
                confidence=0.0,
                status=self._fallback_status(),
                metadata={"error": str(e), "sdk_result": False},
            )

        # è§£æçµæ§‹åŒ–è¼¸å‡ºï¼ˆå…·å‚™è‡ªæˆ‘ä¿®å¾©ï¼‰
        output = self._safe_parse_output(result)
        if output is None:
            logger.error("è§£æ Evaluate è¼¸å‡ºå¤±æ•—ï¼Œå›å‚³å®‰å…¨é è¨­å€¼ã€‚")
            return EvaluationResult(
                final_answer="ç„¡æ³•è§£ææ¨¡å‹è¼¸å‡ºã€‚",
                sources=[],
                confidence=0.0,
                status=self._fallback_status(),
                metadata={
                    "error": "failed_to_parse_output",
                    "raw_output": getattr(result, "output", None),
                },
            )

        # ç‹€æ…‹æ˜ å°„ç‚º AgentDecision
        status_enum = self._map_status_to_agent_decision(output.status)

        # metadata åˆä½µï¼ˆè£œä¸Š analysis åŸå§‹ä¿¡å¿ƒèˆ‡åŸå•é¡Œï¼‰
        result_metadata: Dict[str, JsonValue] = {}
        if isinstance(output.metadata, dict):
            result_metadata.update(output.metadata)
        result_metadata.setdefault("sdk_result", True)
        result_metadata.setdefault("original_question", getattr(analysis, "query", ""))
        result_metadata.setdefault("analysis_confidence", analysis.confidence)

        # sources å·²ç¶“æ˜¯å­—ä¸²åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨
        sources = output.sources if isinstance(output.sources, list) else []

        return EvaluationResult(
            final_answer=output.final_answer,
            sources=sources,
            confidence=output.confidence,
            status=status_enum,
            metadata=result_metadata,
        )
