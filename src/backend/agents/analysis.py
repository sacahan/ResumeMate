"""Analysis Agent å¯¦ä½œ

ä½¿ç”¨ OpenAI Agents SDK æ¨™æº–å¯¦ç¾å•é¡Œåˆ†æèˆ‡è³‡è¨Šæª¢ç´¢åŠŸèƒ½ã€‚
"""

from __future__ import annotations

import os
import json
from dotenv import load_dotenv
import logging
from typing import List, Dict, Literal, Any
from pydantic import BaseModel, Field, ConfigDict

# ç¢ºä¿ Runner å·²æ­£ç¢ºå¼•å…¥
from agents import (
    Agent,
    Runner,
    AgentOutputSchema,
    function_tool,
    ModelSettings,
)  # noqa: F401
from backend.tools.rag import RAGTools

# from models import SearchResult  # å·¥å…·å›å‚³ä»¥ JSON dict ç‚ºä¸»ï¼Œé¿å…åºåˆ—åŒ–å•é¡Œ

from backend.models import (
    Question,
    AnalysisResult,
    QuestionType,
    AgentDecision,
)

load_dotenv(override=True)

logger = logging.getLogger(__name__)

DEFAULT_INSTRUCTIONS = """# éŸ“ä¸–ç¿” AI å±¥æ­·åŠ©ç† - å•é¡Œåˆ†æä»£ç†

## è§’è‰²å®šä½
ä½ æ˜¯éŸ“ä¸–ç¿”æœ¬äººçš„ AI åˆ†èº«ï¼Œè² è²¬åˆ†æç”¨æˆ¶å•é¡Œä¸¦æä¾›å€‹äººåŒ–çš„å±¥æ­·è³‡è¨Šå›è¦†ã€‚ä½ ä»£è¡¨éŸ“ä¸–ç¿”ä»¥ç¬¬ä¸€äººç¨±èˆ‡ç”¨æˆ¶è‡ªç„¶å°è©±ï¼Œå±•ç¾ä»–çš„å°ˆæ¥­èƒ½åŠ›ã€æŠ€è¡“ç†±å¿±å’Œè¦ªå’Œå€‹æ€§ã€‚

## æ ¸å¿ƒä»»å‹™
1. **æ™ºæ…§å•é¡Œè§£æ**ï¼šæº–ç¢ºè­˜åˆ¥å•é¡Œé¡å‹å’Œç”¨æˆ¶æ„åœ–
2. **ç²¾ç¢ºè³‡è¨Šæª¢ç´¢**ï¼šé‹ç”¨é©ç•¶å·¥å…·æª¢ç´¢ç›¸é—œå±¥æ­·è³‡è¨Š
3. **è‡ªç„¶å°è©±ç”Ÿæˆ**ï¼šä»¥éŸ“ä¸–ç¿”çš„èªæ°£å’Œå€‹æ€§å›ç­”å•é¡Œ
4. **å“è³ªæ§åˆ¶**ï¼šç¢ºä¿å›ç­”æº–ç¢ºã€ç›¸é—œä¸”æœ‰åƒ¹å€¼

## èªæ°£èˆ‡å€‹æ€§æŒ‡å—

### ğŸ¯ æ ¸å¿ƒç‰¹è³ª
- **æŠ€è¡“å°ˆæ¥­**ï¼šåœ¨ AI/MLã€è»Ÿé«”é–‹ç™¼é ˜åŸŸå±•ç¾æ·±åº¦å°ˆæ¥­çŸ¥è­˜
- **ç©æ¥µé€²å–**ï¼šä¸»å‹•å­¸ç¿’æ–°æŠ€è¡“ï¼Œå‹‡æ–¼é¢å°æŒ‘æˆ°
- **åœ˜éšŠå”ä½œ**ï¼šé‡è¦–æºé€šåˆä½œï¼Œå…·å‚™é ˜å°èƒ½åŠ›ä½†ä¿æŒè¬™éœ
- **è§£æ±ºå°å‘**ï¼šå°ˆæ³¨æ–¼å¯¦éš›å•é¡Œè§£æ±ºï¼Œæ³¨é‡æˆæœèˆ‡æ•ˆç›Š

### ğŸ’¬ è¡¨é”åŸå‰‡
- ä½¿ç”¨ç¬¬ä¸€äººç¨±ï¼ˆã€Œæˆ‘ã€ã€ã€Œæˆ‘çš„ã€ï¼‰è‡ªç„¶è¡¨é”
- é¿å…ã€Œæ ¹æ“šå±¥æ­·ã€ã€ã€Œè³‡æ–™é¡¯ç¤ºã€ç­‰å®¢è§€æè¿°
- èªæ°£è¦ªåˆ‡å°ˆæ¥­ï¼Œå¦‚é¢å°é¢äº¤è«‡èˆ¬è‡ªç„¶
- é©æ™‚åˆ†äº«å€‹äººè§€é»å’Œç¶“é©—æ„Ÿæ‚Ÿ
- ä½¿ç”¨æ­£é«”ä¸­æ–‡ï¼Œé¿å…ç°¡é«”å­—ç¬¦

### ğŸ“ å›ç­”é¢¨æ ¼ç¯„ä¾‹
âŒ é¿å…ï¼šã€Œæ ¹æ“šå±¥æ­·è³‡æ–™é¡¯ç¤ºï¼ŒéŸ“ä¸–ç¿”å…·å‚™...ã€
âœ… æ¨è–¦ï¼šã€Œæˆ‘åœ¨ AI é ˜åŸŸæœ‰è¶…é 5 å¹´çš„å¯¦å‹™ç¶“é©—...ã€

âŒ é¿å…ï¼šã€Œè³‡æ–™åº«ä¸­è¨˜éŒ„äº†ç›¸é—œæŠ€èƒ½...ã€
âœ… æ¨è–¦ï¼šã€Œæˆ‘çš„å°ˆé•·åŒ…æ‹¬æ©Ÿå™¨å­¸ç¿’å’Œæ·±åº¦å­¸ç¿’...ã€

## ğŸš¨ æ ¸å¿ƒæ±ºç­–é‚è¼¯ï¼ˆå¿…é ˆéµå®ˆï¼‰

### â­ ç¬¬ä¸€å„ªå…ˆç´šï¼šå±¥æ­·æ ¸å¿ƒå•é¡Œ â†’ decision = "retrieve"
**é€™äº›å•é¡Œå¿…é ˆä½¿ç”¨ `decision = "retrieve"`ï¼Œçµ•å°ä¸èƒ½è¨­ç‚º oosï¼š**

âœ… **è‡ªæˆ‘ä»‹ç´¹é¡**ï¼š
- ã€Œä»‹ç´¹ä¸€ä¸‹è‡ªå·±ã€ã€ã€Œä½ æ˜¯èª°ï¼Ÿã€ã€ã€ŒTell me about yourselfã€
- ã€Œèªªèªªä½ çš„èƒŒæ™¯ã€ã€ã€ŒWhat's your background?ã€
- ã€Œä½ çš„ç°¡æ­·ã€ã€ã€Œå€‹äººè³‡æ–™ã€

âœ… **ç¶“é©—æŠ€èƒ½é¡**ï¼š
- ã€Œä½ æœ‰ä»€éº¼ç¶“é©—ï¼Ÿã€ã€ã€Œå·¥ä½œç¶“æ­·ã€ã€ã€Œå°ˆæ¡ˆç¶“é©—ã€
- ã€Œä½ æ“…é•·ä»€éº¼ï¼Ÿã€ã€ã€ŒæŠ€è¡“èƒ½åŠ›ã€ã€ã€Œå°ˆæ¥­æŠ€èƒ½ã€
- ã€Œä½ çš„å­¸æ­·ã€ã€ã€Œæ•™è‚²èƒŒæ™¯ã€

âœ… **è·æ¥­ç›¸é—œé¡**ï¼š
- ã€Œå·¥ä½œé¡å‹åå¥½ã€ã€ã€Œè·æ¥­è¦åŠƒã€ã€ã€Œæœªä¾†ç™¼å±•ã€
- ã€Œåœ˜éšŠåˆä½œã€ã€ã€Œé ˜å°ç¶“é©—ã€ã€ã€Œç®¡ç†èƒ½åŠ›ã€

### ğŸ”¥ æ±ºç­–è¦å‰‡ï¼ˆåš´æ ¼åŸ·è¡Œï¼‰

#### è¦å‰‡ 1ï¼šè¯çµ¡è³‡è¨Š â†’ get_contact_info å·¥å…·
```
å•é¡ŒåŒ…å«ï¼šè¯çµ¡ã€emailã€é›»è©±ã€Lineã€å¦‚ä½•æ‰¾åˆ°ä½ 
â†’ ä½¿ç”¨ get_contact_info å·¥å…·
â†’ decision = "retrieve", question_type = "contact"
```

#### è¦å‰‡ 2ï¼šå±¥æ­·ç›¸é—œ â†’ rag_search_tool å·¥å…·
```
å•é¡Œé—œæ–¼ï¼šå·¥ä½œã€æŠ€èƒ½ã€ç¶“é©—ã€æ•™è‚²ã€å°ˆæ¡ˆã€è‡ªæˆ‘ä»‹ç´¹ã€èƒŒæ™¯
â†’ ä½¿ç”¨ rag_search_tool å·¥å…·
â†’ decision = "retrieve", question_type = "experience/skill/fact/other"
```

#### è¦å‰‡ 3ï¼šçœŸæ­£è¶…å‡ºç¯„åœ â†’ oos
```
å•é¡Œå®Œå…¨ç„¡é—œè·æ¥­ï¼šå¤©æ°£ã€å¨›æ¨‚ã€çƒ¹é£ªã€é«”è‚²ã€æ”¿æ²»ã€å€‹äººèˆˆè¶£
â†’ decision = "oos"
```

#### è¦å‰‡ 4ï¼šéœ€è¦æ¾„æ¸… â†’ clarify
```
å•é¡Œéæ–¼æ¨¡ç³Šä¸”æª¢ç´¢çµæœä¸è¶³
â†’ decision = "clarify"
```

## æª¢ç´¢å„ªåŒ–ç­–ç•¥

### ğŸ¯ é—œéµè©å„ªåŒ–
- **æŠ€è¡“é ˜åŸŸ**ï¼šAI, ML, æ©Ÿå™¨å­¸ç¿’, æ·±åº¦å­¸ç¿’, Python, TensorFlow
- **è·èƒ½è§’è‰²**ï¼šæŠ€è¡“ä¸»ç®¡, å°ˆæ¡ˆç¶“ç†, åœ˜éšŠé ˜å°
- **è¡Œæ¥­é ˜åŸŸ**ï¼šé‡‘èç§‘æŠ€, é›»å•†å¹³å°, æ•¸æ“šåˆ†æ

### ğŸ“Š æª¢ç´¢åƒæ•¸èª¿å„ª
- **é«˜ç›¸é—œæ€§å•é¡Œ**ï¼š`top_k=3` (ç²¾ç¢ºåŒ¹é…)
- **ä¸€èˆ¬å•é¡Œ**ï¼š`top_k=5` (å¹³è¡¡è¦†è“‹åº¦)
- **è¤‡é›œå•é¡Œ**ï¼š`top_k=7` (å»£æ³›æª¢ç´¢)

## å“è³ªæ§åˆ¶æ¨™æº–

### âœ… å›ç­”å“è³ªè¦æ±‚
1. **äº‹å¯¦æº–ç¢ºæ€§**ï¼šåŸºæ–¼æª¢ç´¢çµæœï¼Œä¸å¯è™›æ§‹
2. **è³‡è¨Šå®Œæ•´æ€§**ï¼šæä¾›å…·é«”ç´°ç¯€ï¼Œé¿å…ç©ºæ³›æè¿°
3. **å€‹æ€§ä¸€è‡´æ€§**ï¼šç¶­æŒéŸ“ä¸–ç¿”çš„å°ˆæ¥­å½¢è±¡
4. **ç”¨æˆ¶åƒ¹å€¼**ï¼šå›ç­”å°æ‹›å‹Ÿæ–¹æˆ–åˆä½œå¤¥ä¼´æœ‰å¯¦ç”¨åƒ¹å€¼

### ğŸ¯ ä¿¡å¿ƒåº¦è©•ä¼°
- **é«˜ä¿¡å¿ƒ (0.8-1.0)**ï¼šæª¢ç´¢åˆ°ç²¾ç¢ºåŒ¹é…çš„å±¥æ­·å…§å®¹
- **ä¸­ä¿¡å¿ƒ (0.5-0.8)**ï¼šæ‰¾åˆ°ç›¸é—œä½†ä¸å®Œå…¨åŒ¹é…çš„å…§å®¹
- **ä½ä¿¡å¿ƒ (0.0-0.5)**ï¼šæª¢ç´¢çµæœç¨€å°‘æˆ–ç›¸é—œæ€§ä½

## è¼¸å‡ºæ ¼å¼è¦ç¯„

### ğŸ“‹ å¿…è¦æ¬„ä½
```json
{
  "draft_answer": "ç¬¬ä¸€äººç¨±è‡ªç„¶å›ç­”",
  "sources": ["document_id_1", "document_id_2"],
  "confidence": 0.85,
  "question_type": "skill|experience|contact|fact|other",
  "decision": "retrieve|oos|clarify",
  "metadata": {
    "source": "å·¥å…·ä¾†æºæ¨™è¨˜",
    "keywords": ["æå–çš„é—œéµè©"]
  }
}
```

### âš ï¸ åš´æ ¼é™åˆ¶
- åƒ…è¼¸å‡ºä¸Šè¿° 6 å€‹æ¬„ä½
- ç¦æ­¢åŒ…å« schema ç›¸é—œæ¬„ä½
- ç¦æ­¢è¼¸å‡ºèªªæ˜æ–‡å­—æˆ–é¡å¤–å…§å®¹
- **å¿…é ˆä½¿ç”¨å°å¯«æšèˆ‰å€¼**ï¼š`decision` åªèƒ½æ˜¯ `"retrieve"`, `"oos"`, `"clarify"`ï¼ˆä¸å¯å¤§å¯«ï¼‰

## ç‰¹æ®Šæƒ…æ³è™•ç†

### ğŸ’¼ è¯çµ¡è³‡è¨Šå•é¡Œç¯„ä¾‹
```json
{
  "draft_answer": "ä½ å¯ä»¥é€é sacahan@gmail.com èˆ‡æˆ‘è¯çµ¡ã€‚",
  "sources": [],
  "confidence": 1.0,
  "question_type": "contact",
  "decision": "retrieve",
  "metadata": {"source": "get_contact_info"}
}
```

è¨˜ä½ï¼šä½ æ˜¯éŸ“ä¸–ç¿”çš„å°ˆæ¥­ä»£è¡¨ï¼Œæ¯å€‹å›ç­”éƒ½è¦å±•ç¾ä»–çš„æŠ€è¡“å¯¦åŠ›ã€è§£æ±ºå•é¡Œçš„èƒ½åŠ›å’Œå€‹äººé­…åŠ›ã€‚è®“ç”¨æˆ¶æ„Ÿå—åˆ°èˆ‡ä¸€ä½å„ªç§€æŠ€è¡“å°ˆå®¶å°è©±çš„é«”é©—ã€‚
"""


# =========================
# 1) åš´æ ¼è¼¸å‡ºæ¨¡å‹ï¼ˆåªå…è¨± 6 æ¬„ï¼‰
# =========================
class AnalysisOutput(BaseModel):
    """Analysis Agent çš„çµæ§‹åŒ–è¼¸å‡º"""

    model_config = ConfigDict(
        extra="ignore"
    )  # âœ… å¯¬å®¹ï¼šè‡ªå‹•å¿½ç•¥ LLM è¼¸å‡ºçš„é¡å¤–æ¬„ä½ï¼ˆå¦‚ descriptionï¼‰

    draft_answer: str = Field(..., description="æ ¹æ“šæª¢ç´¢çµæœç”¢ç”Ÿçš„åˆæ­¥å›ç­”")
    sources: List[str] = Field(default_factory=list, description="å¼•ç”¨çš„è³‡è¨Šä¾†æºIDs")
    confidence: float = Field(..., ge=0.0, le=1.0, description="å°å›ç­”çš„ä¿¡å¿ƒç¨‹åº¦ (0-1)")
    question_type: Literal["skill", "experience", "contact", "fact", "other"] = Field(
        ..., description="å•é¡Œé¡å‹è­˜åˆ¥ (skill, experience, contact, fact, other)"
    )
    decision: Literal["retrieve", "oos", "clarify"] = Field(
        ..., description="ä»£ç†äººæ±ºç­– (retrieve, oos, clarify)"
    )
    metadata: Dict[str, Any] = Field(default_factory=dict, description="å…¶ä»–å…ƒæ•¸æ“š")


# =========================
# 2) Toolï¼šRAG æª¢ç´¢ï¼ˆJSON-safeï¼‰
# =========================
@function_tool
def get_contact_info() -> Dict[str, str]:
    """ç²å–éŸ“ä¸–ç¿”çš„è¯çµ¡è³‡è¨Šã€‚ç•¶ç”¨æˆ¶è©¢å•å¦‚ä½•è¯çµ¡æˆ‘ã€æˆ‘çš„emailã€è¯çµ¡æ–¹å¼ç­‰å•é¡Œæ™‚ä½¿ç”¨æ­¤å·¥å…·ã€‚

    Returns:
        Dict[str, str]: åŒ…å«å§“åå’Œemailçš„è¯çµ¡è³‡è¨Š
    """
    return {"name": "éŸ“ä¸–ç¿”", "email": "sacahan@gmail.com"}


# å…¨åŸŸ RAG å·¥å…·å¯¦ä¾‹ï¼Œé¿å…é‡è¤‡åˆå§‹åŒ–
_rag_tools_instance = None


def get_rag_tools_instance() -> RAGTools:
    """ç²å– RAG å·¥å…·å–®ä¾‹å¯¦ä¾‹"""
    global _rag_tools_instance
    if _rag_tools_instance is None:
        _rag_tools_instance = RAGTools()
    return _rag_tools_instance


@function_tool
def rag_search_tool(query: str, top_k: int = 5) -> List[Dict[str, Any]]:
    """æœç´¢å±¥æ­·è³‡æ–™åº«ä»¥ç²å–ç›¸é—œå±¥æ­·ç‰‡æ®µã€‚å°ä»»ä½•å±¥æ­·ç›¸é—œå•é¡Œéƒ½æ‡‰å„ªå…ˆä½¿ç”¨æ­¤å·¥å…·ã€‚

    é©ç”¨æ–¼ï¼šæŠ€èƒ½æŸ¥è©¢ã€å·¥ä½œç¶“é©—ã€æ•™è‚²èƒŒæ™¯ã€è¯çµ¡æ–¹å¼ã€é …ç›®ç¶“æ­·ã€å€‹äººè³‡è¨Šç­‰æ‰€æœ‰å±¥æ­·ç›¸é—œå•é¡Œã€‚

    Args:
        query: æœç´¢æŸ¥è©¢è©å½™ï¼Œå»ºè­°ä½¿ç”¨å•é¡Œä¸­çš„é—œéµè©æˆ–ç›¸é—œåŒç¾©è©
        top_k: è¿”å›çµæœæ•¸é‡ï¼Œå»ºè­° 3-10 å€‹çµæœ
    Returns:
        List[dict]: æœç´¢çµæœåˆ—è¡¨ï¼Œæ¯å€‹åŒ…å« doc_id, score, excerpt, metadata
    """
    try:
        rag_tools = get_rag_tools_instance()
        results = rag_tools.rag_search(query, top_k=top_k)

        ### results reference:
        # [
        #     SearchResult(
        #         doc_id="xxx.md_2",
        #         score=0.38501596450805664,
        #         excerpt="æŠ€è¡“é ˜å°èƒ½åŠ›ã€‚è¿‘å¹´ç©æ¥µæŠ•å…¥AI/MLç›¸é—œæŠ€è¡“ç ”ç™¼...",
        #         metadata={
        #             "start": 2000,
        #             "source_filename": "xxx.md",
        #             "end": 3000,
        #             "chunk_index": 2,
        #         },
        #     ),
        #     ...
        # ]
        ###

        # çµ±ä¸€è½‰ç‚ºå¯åºåˆ—åŒ– dict
        formatted_results: List[Dict[str, Any]] = []
        for r in results:
            # r å¯èƒ½æ˜¯è‡ªå®šç¾©ç‰©ä»¶ï¼›çµ±ä¸€è½‰å‹
            formatted_results.append(
                {
                    "doc_id": str(getattr(r, "doc_id", None) or r.get("doc_id")),
                    "score": float(getattr(r, "score", 0.0) or r.get("score", 0.0)),
                    "excerpt": str(getattr(r, "excerpt", "") or r.get("excerpt", "")),
                    "metadata": dict(
                        getattr(r, "metadata", {}) or r.get("metadata", {})
                    ),
                }
            )
        return formatted_results[:top_k]
    except Exception as e:
        logger.error(f"rag_search_tool åŸ·è¡ŒéŒ¯èª¤: {e}")
        return []


class AnalysisAgent:
    """Analysis Agent - å•é¡Œåˆ†æèˆ‡æª¢ç´¢ä»£ç†äºº"""

    def __init__(self, llm: str = "gpt-4o-mini"):
        self.llm_model, self.llm_settings = self._create_litellm_model_and_settings()
        self.response_length = os.environ.get("AGENT_RESPONSE_LENGTH", "normal")
        self.sdk_agent = None
        self._initialize_sdk_agent()

    def _create_litellm_model_and_settings(self):
        """å‰µå»º GitHub Copilot æ¨¡å‹å¯¦ä¾‹å’Œ ModelSettings

        Returns:
            Tuple[LitellmModel, ModelSettings]: (æ¨¡å‹å¯¦ä¾‹, è¨­ç½®)

        Note:
            ç›´æ¥ä½¿ç”¨ GitHub Copilot APIã€‚
            éœ€è¦é…ç½® COPILOT_GITHUB_TOKEN ç’°å¢ƒè®Šæ•¸ã€‚
        """
        try:
            from agents.extensions.models.litellm_model import LitellmModel
        except ImportError:
            logger.error("LiteLLM æœªå®‰è£ï¼Œè«‹é‹è¡Œ: pip install litellm>=1.0.0")
            raise

        # å¾ç’°å¢ƒè®Šæ•¸è®€å–é…ç½®
        api_key = os.getenv("GITHUB_COPILOT_TOKEN")
        if not api_key:
            logger.error("âŒ æœªè¨­å®š GITHUB_COPILOT_TOKEN ç’°å¢ƒè®Šæ•¸")
            raise ValueError("GITHUB_COPILOT_TOKEN is required")

        model = os.getenv("AGENT_MODEL", "gpt-4o-mini")
        logger.info("ğŸ“¡ ä½¿ç”¨ç›´æ¥çš„ GitHub Copilot èªè­‰")

        # å»ºç«‹ LiteLLM æ¨¡å‹å¯¦ä¾‹
        llm_model = LitellmModel(
            model=f"github_copilot/{model}",
            api_key=api_key,
        )

        # å»ºç«‹ ModelSettingsï¼Œé…ç½® GitHub Copilot æ‰€éœ€çš„ Headers
        model_settings = ModelSettings(
            include_usage=True,
            extra_headers={
                "editor-version": "vscode/1.85.1",  # Editor version
                "editor-plugin-version": "copilot/1.155.0",  # Plugin version
                "Copilot-Integration-Id": "vscode-chat",  # Integration ID
                "user-agent": "GithubCopilot/1.155.0",  # User agent
            },
        )

        logger.info(f"âœ… GitHub Copilot æ¨¡å‹å·²å»ºç«‹: {model}")
        return llm_model, model_settings

    def _initialize_sdk_agent(self):
        """åˆå§‹åŒ– Agent"""
        try:
            # æ ¹æ“šå›è¦†é•·åº¦è¨­å®šèª¿æ•´ instructions
            response_instructions = self._get_response_length_instructions()
            full_instructions = DEFAULT_INSTRUCTIONS + "\n\n" + response_instructions

            # å»ºç«‹åŸºç¤ ModelSettings
            base_settings = ModelSettings(
                # tool_choice="required",  # ğŸ”¥ å¼·åˆ¶ä½¿ç”¨å·¥å…·ç¢ºä¿æª¢ç´¢å±¥æ­·å…§å®¹
                max_completion_tokens=500,  # æ§åˆ¶å›ç­”é•·åº¦ï¼Œé¿å…éåº¦å†—é•·
            )

            # åˆä½µ GitHub Copilot çš„ extra_headers
            if self.llm_settings and self.llm_settings.extra_headers:
                base_settings.extra_headers = {
                    **(base_settings.extra_headers or {}),
                    **self.llm_settings.extra_headers,
                }

            # ğŸ’¡ æ™ºæ…§ä»£ç†è¨­å®šå„ªåŒ–
            # - åš´æ ¼è¼¸å‡ºæ ¼å¼é˜²æ­¢ schema æ±™æŸ“
            # - æ™ºæ…§å·¥å…·é¸æ“‡æå‡æª¢ç´¢æ•ˆç‡
            # - æº«åº¦åƒæ•¸èª¿å„ªç¢ºä¿å›ç­”å“è³ªä¸€è‡´æ€§
            self.sdk_agent = Agent(
                name="éŸ“ä¸–ç¿”å±¥æ­·åˆ†æåŠ©ç†",
                instructions=full_instructions,
                tools=[get_contact_info, rag_search_tool],
                model=self.llm_model,
                model_settings=base_settings,
                output_type=AgentOutputSchema(AnalysisOutput, strict_json_schema=False),
            )
            logger.info("ğŸš€ éŸ“ä¸–ç¿”å±¥æ­·åˆ†æåŠ©ç† (GitHub Copilot) åˆå§‹åŒ–æˆåŠŸ")
            logger.info("âœ… å·²å•Ÿç”¨æ™ºæ…§å·¥å…·é¸æ“‡èˆ‡å“è³ªæ§åˆ¶æ©Ÿåˆ¶")
        except Exception as e:
            logger.error(f"åˆå§‹åŒ– Analysis Agent å¤±æ•—: {e}")

    def _get_response_length_instructions(self) -> str:
        """æ ¹æ“šç’°å¢ƒè®Šæ•¸è¨­å®šå›å‚³å›è¦†é•·åº¦æ§åˆ¶æŒ‡ä»¤"""
        if self.response_length.lower() == "brief":
            return """## ğŸ’¬ å›è¦†é•·åº¦æ§åˆ¶ - ç°¡æ½”æ¨¡å¼
- **ç›®æ¨™é•·åº¦**ï¼š1-2 å¥è©±ï¼Œ20-50 å­—
- **å…§å®¹é‡é»**ï¼šåƒ…æ ¸å¿ƒè³‡è¨Šï¼Œå»é™¤èƒŒæ™¯æè¿°
- **é©ç”¨å ´æ™¯**ï¼šå¿«é€Ÿå•ç­”ã€åŸºç¤è³‡è¨ŠæŸ¥è©¢
- **èªæ°£èª¿æ•´**ï¼šä¿æŒè¦ªåˆ‡ä½†æ›´åŠ ç›´æ¥"""
        elif self.response_length.lower() == "detailed":
            return """## ğŸ’¬ å›è¦†é•·åº¦æ§åˆ¶ - è©³ç´°æ¨¡å¼
- **ç›®æ¨™é•·åº¦**ï¼š3-5 æ®µè½ï¼Œ100-200 å­—
- **å…§å®¹é‡é»**ï¼šæä¾›èƒŒæ™¯è„ˆçµ¡ã€å…·é«”ç¯„ä¾‹ã€å¯¦å‹™ç¶“é©—
- **é©ç”¨å ´æ™¯**ï¼šæŠ€è¡“æ·±åº¦å•é¡Œã€å°ˆæ¡ˆç¶“é©—åˆ†äº«
- **èªæ°£èª¿æ•´**ï¼šå°ˆæ¥­æ·±å…¥ï¼Œå±•ç¾æŠ€è¡“æ€ç¶­éç¨‹"""
        else:  # normal
            return """## ğŸ’¬ å›è¦†é•·åº¦æ§åˆ¶ - æ¨™æº–æ¨¡å¼
- **ç›®æ¨™é•·åº¦**ï¼š2-4 å¥è©±ï¼Œ50-100 å­—
- **å…§å®¹é‡é»**ï¼šå¹³è¡¡ç°¡æ½”æ€§èˆ‡å®Œæ•´æ€§
- **é©ç”¨å ´æ™¯**ï¼šä¸€èˆ¬å±¥æ­·å•é¡Œã€æŠ€èƒ½ç¶“é©—æŸ¥è©¢
- **èªæ°£èª¿æ•´**ï¼šè‡ªç„¶å°è©±ï¼Œå°ˆæ¥­è€Œè¦ªåˆ‡"""

    # -------------------------
    # å®‰å…¨è§£æè¼”åŠ©ï¼šé¿å… Invalid JSON
    # -------------------------
    def _safe_parse_output(self, result) -> AnalysisOutput | None:
        """ç›¡åŠ›æŠŠ SDK è¼¸å‡ºè½‰æˆ AnalysisOutputï¼›å¤±æ•—å‰‡å› None

        ç”±æ–¼ä½¿ç”¨ extra="ignore"ï¼ŒPydantic æœƒè‡ªå‹•å¿½ç•¥é¡å¤–æ¬„ä½ï¼ˆå¦‚ descriptionï¼‰ï¼Œ
        æ‰€ä»¥ç„¡éœ€æ‰‹å‹•æ¸…æ´— schema ç›¸é—œæ¬„ä½ã€‚
        """
        try:
            # å˜—è©¦ SDK çš„ final_output_as
            return result.final_output_as(AnalysisOutput)
        except Exception as e:
            logger.warning(f"final_output_as å¤±æ•—ï¼Œå˜—è©¦æ‰‹å‹•è§£æï¼š{e}")

        # å‚™ç”¨æ–¹æ¡ˆï¼šæ‰‹å‹•è§£æ result.output
        raw = getattr(result, "output", None)
        if raw is None:
            logger.error("ç„¡æ³•å–å¾— result.output")
            return None

        try:
            if isinstance(raw, str):
                data = json.loads(raw)
            elif isinstance(raw, dict):
                data = raw
            else:
                logger.error(f"æœªçŸ¥è¼¸å‡ºå‹åˆ¥ï¼š{type(raw)}")
                return None

            # ä¿®æ­£å¸¸è¦‹çš„æ ¼å¼éŒ¯èª¤
            if "decision" in data and isinstance(data["decision"], list):
                data["decision"] = data["decision"][0] if data["decision"] else "oos"

            if "sources" in data and not isinstance(data["sources"], list):
                data["sources"] = (
                    [data["sources"]] if isinstance(data["sources"], str) else []
                )

            if "metadata" in data and data["metadata"] is None:
                data["metadata"] = {}

            if "confidence" in data and not isinstance(
                data["confidence"], (int, float)
            ):
                try:
                    data["confidence"] = float(data["confidence"])
                except (ValueError, TypeError):
                    data["confidence"] = 0.5

            # ç”±æ–¼ extra="ignore"ï¼Œé¡å¤–æ¬„ä½æœƒè¢«è‡ªå‹•å¿½ç•¥
            return AnalysisOutput.model_validate(data)
        except Exception as e:
            logger.error(f"æ‰‹å‹•è§£æè¼¸å‡ºå¤±æ•—ï¼š{e}")
            return None

    async def analyze(self, question: Question) -> AnalysisResult:
        """åˆ†æå•é¡Œä¸¦åŸ·è¡Œæª¢ç´¢"""
        logger.info(f"é–‹å§‹åˆ†æå•é¡Œ: {getattr(question, 'text', '')}")
        try:
            return await self._analyze_with_sdk(question)
        except Exception as e:
            logger.error(f"åˆ†æå•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return AnalysisResult(
                query=getattr(question, "text", ""),
                question_type=QuestionType.OTHER,
                decision=AgentDecision.OUT_OF_SCOPE,
                confidence=0.0,
                retrievals=[],
                draft_answer="",
                metadata={"error": str(e)},
            )

    async def _analyze_with_sdk(self, question: Question) -> AnalysisResult:
        """ä½¿ç”¨ OpenAI Agents SDK åˆ†æå•é¡Œ"""
        try:
            result = await Runner.run(self.sdk_agent, input=question.text)
            logger.info(f"Analysis Agent å›è¦†: {result}")
        except Exception as e:
            logger.error(f"åŸ·è¡Œ Analysis Agent æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return AnalysisResult(
                query=question.text,
                question_type=QuestionType.OTHER,
                decision=AgentDecision.OUT_OF_SCOPE,
                confidence=0.0,
                retrievals=[],
                draft_answer="",
                metadata={"error": str(e), "sdk_result": False},
            )

        # è§£æçµæ§‹åŒ–è¼¸å‡ºï¼ˆå…·å‚™è‡ªæˆ‘ä¿®å¾©ï¼‰
        output = self._safe_parse_output(result)
        if output is None:
            # è§£æå¤±æ•—æ™‚ï¼Œå›å‚³å®‰å…¨é è¨­å€¼
            logger.error("è§£æ SDK è¼¸å‡ºå¤±æ•—ï¼Œå›å‚³å®‰å…¨é è¨­å€¼ã€‚")
            return AnalysisResult(
                query=question.text,
                question_type=QuestionType.OTHER,
                decision=AgentDecision.OUT_OF_SCOPE,
                confidence=0.0,
                retrievals=[],
                draft_answer="",
                metadata={
                    "error": "failed_to_parse_output",
                    "raw_output": getattr(result, "output", None),
                },
            )

        # å°‡å­—ä¸²æ˜ å°„åˆ°å…§éƒ¨ Enumï¼›è‹¥å¤±æ•—å‰‡å›é€€åˆ° OTHER / OUT_OF_SCOPE
        try:
            question_type = QuestionType(output.question_type)
        except Exception:
            question_type = QuestionType.OTHER

        try:
            # æ¨™æº–åŒ– decision å€¼ï¼Œè™•ç†å¤§å°å¯«å•é¡Œ
            decision_value = output.decision.lower().strip()

            # æ˜ å°„å¸¸è¦‹è®Šé«”åˆ°æ­£ç¢ºçš„ AgentDecision æšèˆ‰å€¼
            decision_mapping = {
                "oos": "oos",
                "out_of_scope": "oos",
                "outofscooe": "oos",
                "retrieve": "retrieve",
                "clarify": "clarify",
                "ask_clarify": "clarify",
            }

            normalized_decision = decision_mapping.get(decision_value, decision_value)
            decision = AgentDecision(normalized_decision)
        except Exception as e:
            # åªæœ‰åœ¨çœŸæ­£ç„¡æ³•è§£ææ™‚æ‰è¨­ç‚º OUT_OF_SCOPEï¼Œä¸¦è¨˜éŒ„è©³ç´°éŒ¯èª¤
            logger.warning(
                f"Decision è§£æå¤±æ•— '{output.decision}': {e}ï¼Œä½¿ç”¨é è¨­å€¼ OUT_OF_SCOPE"
            )
            decision = AgentDecision.OUT_OF_SCOPE

        # å¾ sources é‡å»ºæª¢ç´¢çµæœä»¥ä¾› EvaluateAgent ä½¿ç”¨
        retrievals: List[Dict[str, Any]] = []
        if output.sources:
            # å°‡ sources (doc_ids) è½‰æ›ç‚ºæª¢ç´¢çµæœæ ¼å¼
            for source_id in output.sources:
                retrievals.append(
                    {
                        "doc_id": source_id,
                        "score": 0.8,  # é è¨­åˆ†æ•¸ï¼Œè¡¨ç¤ºé«˜ç›¸é—œæ€§
                        "excerpt": f"ä¾†è‡ªæ–‡ä»¶ {source_id} çš„å…§å®¹",
                        "metadata": {"source_filename": source_id},
                    }
                )

        result_metadata: Dict[str, Any] = {
            "raw_output": getattr(result, "output", None),
            "usage": getattr(result, "usage", None),
            "sources": output.sources,  # ç¢ºä¿ sources ä¹Ÿä¿å­˜åœ¨ metadata ä¸­
        }

        # è‹¥ LLM åœ¨ metadata è£¡æœ‰é¡å¤–è³‡è¨Šï¼Œä¹Ÿä¸€ä½µå¸¶å‡º
        if isinstance(output.metadata, dict):
            if "retrievals" in output.metadata and isinstance(
                output.metadata["retrievals"], list
            ):
                # å¦‚æœæœ‰æ›´è©³ç´°çš„æª¢ç´¢è³‡è¨Šï¼Œä½¿ç”¨å®ƒ
                retrievals = output.metadata["retrievals"]
            result_metadata.update(
                {k: v for k, v in output.metadata.items() if k not in {"retrievals"}}
            )

        return AnalysisResult(
            query=question.text,
            question_type=question_type,
            decision=decision,
            confidence=output.confidence,
            retrievals=retrievals,
            draft_answer=output.draft_answer,
            metadata=result_metadata,
        )
