"""ResumeMate Gradio æ‡‰ç”¨ç¨‹å¼

æä¾› AI å±¥æ­·å•ç­”ä»‹é¢
"""

import logging
import sys
import os

# ä¿®å¾© Gradio ç’°å¢ƒè®Šæ•¸å•é¡Œ
if os.getenv("GRADIO_SERVER_PORT") == "":
    os.environ.pop("GRADIO_SERVER_PORT", None)

# ç¢ºä¿å…¶ä»– Gradio ç’°å¢ƒè®Šæ•¸çš„æ­£ç¢ºæ€§
gradio_env_vars = ["GRADIO_SERVER_NAME", "GRADIO_SHARE", "GRADIO_DEBUG"]
for var in gradio_env_vars:
    if os.getenv(var) == "":
        os.environ.pop(var, None)

# æ·»åŠ  src ç›®éŒ„åˆ° Python è·¯å¾‘ï¼ˆå¿…é ˆåœ¨ gradio å°å…¥ä¹‹å‰ï¼‰
sys.path.append(os.path.join(os.path.dirname(__file__), "src"))

# é‡è¦ï¼šgradio å¿…é ˆåœ¨ç’°å¢ƒè®Šæ•¸ä¿®å¾©å¾Œæ‰èƒ½å°å…¥
import gradio as gr  # noqa: E402

from agents import trace, set_default_openai_api  # noqa: E402

# ğŸ”§ è¨­ç½®ä½¿ç”¨ Chat Completions API è€Œé Responses API ä»¥é¿å…æ¨ç†éŒ¯èª¤
set_default_openai_api("chat_completions")
from src.backend.models import Question  # noqa: E402
from src.backend.processor import ResumeMateProcessor  # noqa: E402
from src.backend.tools.contact import (  # noqa: E402
    ContactManager,
    generate_contact_request_message,
    is_contact_info_input,
)


# è¿½è¹¤åŠŸèƒ½å·²å•Ÿç”¨æ¨™è¨˜
TRACING_AVAILABLE = True

# è¨­å®šæ—¥èªŒ
from src.backend.logging_config import configure_logging  # noqa: E402

# å¾ç’°å¢ƒè®Šæ•¸è®€å–æ—¥èªŒé…ç½®
LOG_CONSOLE_LEVEL = os.getenv("LOG_CONSOLE_LEVEL", "INFO")
LOG_FILE_LEVEL = os.getenv("LOG_FILE_LEVEL", "DEBUG")
LOG_FILE = os.getenv("LOG_FILE", "logs/resumemate.log")

configure_logging(
    console_level=LOG_CONSOLE_LEVEL,
    file_level=LOG_FILE_LEVEL,
    log_file=LOG_FILE,
)

logger = logging.getLogger(__name__)

# åˆå§‹åŒ–è™•ç†å™¨
try:
    processor = ResumeMateProcessor()
    logger.info("ResumeMate è™•ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    logger.error(f"åˆå§‹åŒ–è™•ç†å™¨å¤±æ•—: {e}")
    processor = None

# åˆå§‹åŒ–è¯çµ¡è³‡è¨Šç®¡ç†å™¨
contact_manager = ContactManager()

# èªè¨€é…ç½® - åƒ…ä¸­æ–‡
TEXTS = {
    "title": "ğŸ¤– ResumeMate - AI å±¥æ­·åŠ©æ‰‹",
    "description": "é€™æ˜¯ä¸€å€‹ç”± RAG æŠ€è¡“é©…å‹•çš„ AI ä»£ç†äººå±•ç¤ºã€‚æ‚¨å¯ä»¥è©¢å•é—œæ–¼æˆ‘çš„æŠ€èƒ½ã€ç¶“é©—ã€æ•™è‚²ã€è¯çµ¡è³‡è¨Šç­‰å•é¡Œã€‚",
    "chat_label": "å°è©±",
    "chat_placeholder": "ç›®å‰é‚„æ²’æœ‰å°è©±è¨˜éŒ„...",
    "input_label": "æ‚¨çš„å•é¡Œ",
    "input_placeholder": "ä¾‹å¦‚ï¼šä½ çš„å·¥ä½œç¶“é©—ï¼Ÿ",
    "send_button": "ç™¼é€",
    "examples_label": "ç¯„ä¾‹å•é¡Œ",
    "examples": [
        "ä»‹ç´¹ä¸€ä¸‹è‡ªå·±",
        "ä½ çš„å­¸ç¶“æ­·ï¼Ÿ",
        "ä½ æ“…é•·çš„æŠ€è¡“ï¼Ÿ",
        "åå¥½çš„å·¥ä½œé¡å‹ï¼Ÿ",
        "å¦‚ä½•è¯çµ¡ä½ ï¼Ÿ",
    ],
    "thinking": "æ­£åœ¨æ€è€ƒæ‚¨çš„å•é¡Œ...",
    "processing": "è™•ç†ä¸­...",
    "clarify_title": "è£œå……è³‡è¨Šï¼ˆç•¶ç³»çµ±éœ€è¦æ›´å¤šè³‡è¨Šæ™‚é¡¯ç¤ºï¼‰",
    "clarify_label": "è«‹è£œå……è³‡è¨Šå¾Œç›´æ¥é€å‡º",
    "clarify_placeholder": "ä¾‹å¦‚ï¼šå…¬å¸åç¨±ã€å¹´ä»½ã€è·ç¨±ã€å°ˆæ¡ˆåç¨±...",
    "clarify_submit": "é€å‡ºè£œå……",
    "status_title": "ç³»çµ±ç‹€æ…‹",
    "refresh_button": "åˆ·æ–°ç‹€æ…‹",
    "low_confidence_hint": "\n\nğŸ’¡ æç¤ºï¼šæ­¤å›ç­”çš„å¯ä¿¡åº¦è¼ƒä½ï¼Œå»ºè­°ä½¿ç”¨æ›´è©³ç´°çš„æå•ã€‚",
    "system_error": "æŠ±æ­‰ï¼Œç³»çµ±åˆå§‹åŒ–å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚",
    "empty_input": "è«‹è¼¸å…¥æ‚¨çš„å•é¡Œã€‚",
    "processing_error": "æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š",
}


async def stream_process_question(user_input: str, history: list):
    """
    ç”¨æ–¼ streaming è¼¸å‡ºçš„è™•ç†å‡½æ•¸ï¼Œæ”¯æ´å°è©±å¼è¯çµ¡è³‡è¨Šæ”¶é›†
    """
    texts = TEXTS

    if not processor:
        yield (
            history + [{"role": "assistant", "content": texts["system_error"]}],
            gr.update(visible=False),
            gr.update(visible=False),
        )
        return

    if not user_input.strip():
        yield (
            history + [{"role": "assistant", "content": texts["empty_input"]}],
            gr.update(visible=False),
            gr.update(visible=False),
        )
        return

    # æª¢æŸ¥æ˜¯å¦æ˜¯è¯çµ¡è³‡è¨Šè¼¸å…¥
    if is_contact_info_input(user_input):
        # å¾æ­·å²ä¸­æ‰¾åˆ°æœ€è¿‘çš„å•é¡Œ
        original_question = None
        for item in reversed(history):
            if item["role"] == "user" and not is_contact_info_input(item["content"]):
                original_question = item["content"]
                break

        # è™•ç†è¯çµ¡è³‡è¨Š
        success, message, contact_info = contact_manager.process_contact_input(
            user_input, original_question
        )

        final_history = history + [{"role": "assistant", "content": message}]
        yield (
            final_history,
            gr.update(visible=False),
            gr.update(visible=False),
        )
        return

    try:
        # å…ˆé¡¯ç¤º "æ­£åœ¨æ€è€ƒ..." çš„è¨Šæ¯
        thinking_history = history + [
            {"role": "assistant", "content": texts["thinking"]}
        ]
        yield (
            thinking_history,
            gr.update(visible=False),
            gr.update(visible=False),
            gr.update(visible=False),
        )

        question = Question(
            text=user_input.strip(),
            language="zh-TW",
            context=(
                [item["content"] for item in history[-6:] if item["role"] == "user"]
                if history
                else None
            ),
        )

        with trace(
            f"ResumeMate: {user_input[:10]}...",
            metadata={"session_id": str(id(history))},
        ):
            response = await processor.process_question(question)

            answer = response.answer or ""

            # å„ªåŒ– streaming æ•ˆæœ - æ¸›å°‘ä¸å¿…è¦å»¶é²
            current_text = answer.strip()
            streaming_history = history + [
                {"role": "assistant", "content": current_text}
            ]
            yield (
                streaming_history,
                gr.update(visible=False),
                gr.update(visible=False),
                gr.update(visible=False),
            )

            # ä½ä¿¡å¿ƒæç¤º
            if response.confidence < 0.3:
                final_answer = current_text.strip() + texts["low_confidence_hint"]
                final_history = history + [
                    {"role": "assistant", "content": final_answer}
                ]
                yield (
                    final_history,
                    gr.update(visible=False),
                    gr.update(visible=False),
                    gr.update(visible=False),
                )

            # æ ¹æ“š SystemResponse.action æ±ºå®š UI å‘ˆç¾
            action_text = ""
            show_clarify = False

            action = (response.action or "").strip()
            meta = response.metadata or {}

            if action == "è«‹æä¾›æ›´å¤šè³‡è¨Š":
                show_clarify = True
                missing = meta.get("missing_fields") or []
                ex = meta.get("clarify_examples") or []
                bullet_missing = (
                    "ã€".join(missing) if missing else "å¿…è¦ç´°ç¯€ï¼ˆå…¬å¸/å¹´ä»½/è·ç¨±ç­‰ï¼‰"
                )
                bullet_examples = (
                    "ï¼›".join(ex)
                    if ex
                    else "ä¾‹å¦‚ï¼šè«‹è£œå……ã€Œ2023 åœ¨ å°ç£ä¹‹æ˜Ÿ æ“”ä»»ä»€éº¼è·å‹™èˆ‡è·è²¬ï¼Ÿã€"
                )
                action_text = (
                    f"ğŸ” éœ€è¦è£œå……è³‡è¨Šï¼šè«‹æä¾› **{bullet_missing}**ã€‚{bullet_examples}"
                )

            elif (
                action == "è«‹å¡«å¯«è¯çµ¡è¡¨å–®"
                or str(meta.get("status", "")).lower() == "escalate_to_human"
                or str(meta.get("status", "")).lower() == "out_of_scope"
            ):
                # ç›´æ¥åœ¨å°è©±ä¸­é¡¯ç¤ºè¯çµ¡è³‡è¨Šè«‹æ±‚
                contact_request_msg = generate_contact_request_message()
                final_answer = current_text.strip() + "\n\n" + contact_request_msg
                final_history = history + [
                    {"role": "assistant", "content": final_answer}
                ]
                yield (
                    final_history,
                    gr.update(visible=False),
                    gr.update(visible=False),
                )
                return

            # æœ€çµ‚å›æ‡‰åŒ…å«æ‰€æœ‰ UI ç‹€æ…‹
            final_history = history + [
                {
                    "role": "assistant",
                    "content": (
                        final_answer
                        if response.confidence < 0.3
                        else current_text.strip()
                    ),
                }
            ]
            yield (
                final_history,
                gr.update(value=action_text, visible=bool(action_text)),
                gr.update(visible=show_clarify),
            )

    except Exception as e:
        logging.getLogger(__name__).error(f"è™•ç†å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        error_msg = f"{texts['processing_error']}{str(e)}"
        error_history = history + [{"role": "assistant", "content": error_msg}]
        yield (
            error_history,
            gr.update(visible=False),
            gr.update(visible=False),
        )


def get_system_status() -> str:
    """å–å¾—ç³»çµ±ç‹€æ…‹"""
    if not processor:
        return "âŒ ç³»çµ±æœªåˆå§‹åŒ–"

    try:
        info = processor.get_system_info()

        # æ·»åŠ è¿½è¹¤ç‹€æ…‹
        tracing_status = "âœ… å·²å•Ÿç”¨" if TRACING_AVAILABLE else "âŒ æœªå•Ÿç”¨"

        status_text = f"""
**ç³»çµ±ç‹€æ…‹**: âœ… æ­£å¸¸é‹è¡Œ
**ç‰ˆæœ¬**: {info["version"]}
**è³‡æ–™åº«**: {info["database"]["document_count"]} å€‹æ–‡ä»¶
**ä»£ç†äºº**: Analysis Agent âœ…, Evaluate Agent âœ…
**è¿½è¹¤åŠŸèƒ½**: {tracing_status}
        """
        return status_text.strip()
    except Exception as e:
        return f"âŒ ç³»çµ±ç‹€æ…‹æª¢æŸ¥å¤±æ•—: {e}"


def create_gradio_interface():
    """
    Create the Gradio interface for the application.
    """

    custom_css = """
    /* åŒ¹é…å‰ç«¯çš„å­—é«”è¨­å®š - åƒ…é‡å° gradio-app çµ„ä»¶ */
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&family=Noto+Sans+TC:wght@400;500;700&display=swap');

    /* é™åˆ¶å­—é«”æ¨£å¼åƒ…æ‡‰ç”¨æ–¼ Gradio å®¹å™¨å…§éƒ¨ */
    .gradio-container *,
    .gradio-container {
        font-family: "Inter", "Noto Sans TC", sans-serif !important;
    }

    /* ä¸»å®¹å™¨æ¨£å¼åŒ¹é…å‰ç«¯ - ç¢ºä¿ä¸å½±éŸ¿å¤–éƒ¨é é¢èƒŒæ™¯ */
    .gradio-container {
        max-width: 800px !important;
        margin: auto !important;
        color: #d1d5db !important;
        /* ç§»é™¤èƒŒæ™¯æ¨£å¼ï¼Œè®“å¤–éƒ¨é é¢æ§åˆ¶èƒŒæ™¯ */
        background: transparent !important;
        padding: 0.5rem !important;
        border-radius: 1rem !important;
    }

    .gradio-container p {
        font-size: 0.9rem !important;
    }

    /* ç»ç’ƒæ•ˆæœåƒ…æ‡‰ç”¨æ–¼ Gradio å…§éƒ¨çµ„ä»¶ */
    .gradio-container .glass-effect {
        background: rgba(255, 255, 255, 0.1) !important;
        backdrop-filter: blur(10px) !important;
        border: 1px solid rgba(255, 255, 255, 0.2) !important;
    }

    /* æ–‡å­—æ¼¸å±¤æ•ˆæœåƒ…æ‡‰ç”¨æ–¼ Gradio å…§éƒ¨ */
    .gradio-container .text-gradient {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        -webkit-background-clip: text !important;
        -webkit-text-fill-color: transparent !important;
        background-clip: text !important;
    }

    /* æ¨™é¡Œæ¨£å¼åƒ…æ‡‰ç”¨æ–¼ Gradio å…§éƒ¨ */
    .gradio-container h1,
    .gradio-container h2,
    .gradio-container h3 {
        color: #d1d5db !important;
        font-size: 1.5rem !important;
        font-weight: 600 !important;
        text-align: left !important;
        margin: 1rem 0 !important;
    }

    /* ç‰¹åˆ¥é‡å°ä¸»æ¨™é¡Œçš„æ¨£å¼ */
    .gradio-container h1:first-of-type {
        font-size: 2rem !important;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        -webkit-background-clip: text !important;
        -webkit-text-fill-color: transparent !important;
        background-clip: text !important;
    }

    /* Gradio çµ„ä»¶æ¨£å¼èª¿æ•´ */
    .gradio-container .chat-message {
        border-radius: 10px !important;
        padding: 10px !important;
        margin: 5px 0 !important;
    }

    /* é‡å° Gradio 4.0+ çš„ Chatbot çµ„ä»¶æ¨£å¼ */
    .gradio-container .message-wrap {
        margin-bottom: 1rem !important;
    }

    /* ç”¨æˆ¶æ¶ˆæ¯é å³å°é½Š */
    .gradio-container .message-wrap[data-testid*="user"] .message {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        color: white !important;
        margin-left: auto !important;
        margin-right: 0 !important;
        max-width: 80% !important;
        border-radius: 18px 18px 4px 18px !important;
        font-family: "Inter", "Noto Sans TC", sans-serif !important;
    }

    /* AI å›è¦†é å·¦å°é½Š - ä½¿ç”¨ç»ç’ƒæ•ˆæœ */
    .gradio-container .message-wrap[data-testid*="bot"] .message,
    .gradio-container .message-wrap[data-testid*="assistant"] .message {
        background: rgba(255, 255, 255, 0.1) !important;
        backdrop-filter: blur(10px) !important;
        border: 1px solid rgba(255, 255, 255, 0.2) !important;
        color: #d1d5db !important;
        margin-left: 0 !important;
        margin-right: auto !important;
        max-width: 80% !important;
        border-radius: 18px 18px 18px 4px !important;
        font-family: "Inter", "Noto Sans TC", sans-serif !important;
    }

    /* æ·±è‰²ä¸»é¡Œæ”¯æ´ */
    .gradio-container.dark .message-wrap[data-testid*="bot"] .message,
    .gradio-container.dark .message-wrap[data-testid*="assistant"] .message {
        background: rgba(255, 255, 255, 0.1) !important;
        color: #d1d5db !important;
    }

    /* è¼¸å…¥æ¡†æ¨£å¼åŒ¹é…å‰ç«¯ - åƒ…å½±éŸ¿ Gradio å…§éƒ¨ */
    .gradio-container input,
    .gradio-container textarea {
        background: rgba(255, 255, 255, 0.1) !important;
        border: 1px solid rgba(255, 255, 255, 0.2) !important;
        color: #d1d5db !important;
        font-family: "Inter", "Noto Sans TC", sans-serif !important;
    }

    /* æŒ‰éˆ•æ¨£å¼åŒ¹é…å‰ç«¯ - åƒ…å½±éŸ¿ Gradio å…§éƒ¨ */
    .gradio-container .btn-primary,
    .gradio-container button[variant="primary"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        border: none !important;
        color: white !important;
        font-family: "Inter", "Noto Sans TC", sans-serif !important;
    }

    /* å…¶ä»–æŒ‰éˆ•ä½¿ç”¨ç»ç’ƒæ•ˆæœ - åƒ…å½±éŸ¿ Gradio å…§éƒ¨ */
    .gradio-container button:not([variant="primary"]) {
        background: rgba(255, 255, 255, 0.1) !important;
        backdrop-filter: blur(10px) !important;
        border: 1px solid rgba(255, 255, 255, 0.2) !important;
        color: #d1d5db !important;
        font-family: "Inter", "Noto Sans TC", sans-serif !important;
    }

    /* è¨Šæ¯å…§å®¹æ¨£å¼å„ªåŒ– - åƒ…å½±éŸ¿ Gradio å…§éƒ¨ */
    .gradio-container .message p {
        margin-bottom: 0.5rem !important;
    }

    .gradio-container .message p:last-child {
        margin-bottom: 0 !important;
    }

    /* è¼‰å…¥ç‹€æ…‹æ¨£å¼ - åƒ…å½±éŸ¿ Gradio å…§éƒ¨ */
    .gradio-container .message-wrap.generating .message {
        opacity: 0.8 !important;
        animation: gradio-pulse 1.5s ease-in-out infinite !important;
    }

    @keyframes gradio-pulse {
        0%, 100% { opacity: 0.8; }
        50% { opacity: 1; }
    }

    /* æŒ‰éˆ•è¼‰å…¥ç‹€æ…‹ - åƒ…å½±éŸ¿ Gradio å…§éƒ¨ */
    .gradio-container .btn-loading {
        opacity: 0.6 !important;
        cursor: not-allowed !important;
    }

    /* Scrollbar æ¨£å¼åƒ…æ‡‰ç”¨æ–¼ Gradio å…§éƒ¨çš„æ»¾å‹•æ¢ */
    .gradio-container ::-webkit-scrollbar {
        width: 8px !important;
    }
    .gradio-container ::-webkit-scrollbar-track {
        background: #1f2937 !important;
    }
    .gradio-container ::-webkit-scrollbar-thumb {
        background: #4b5563 !important;
        border-radius: 4px !important;
    }
    """

    # å‰µå»ºå¼·åˆ¶æ·±è‰²æ¨¡å¼ä¸»é¡Œ
    dark_theme = gr.themes.Soft(
        primary_hue="violet",
        secondary_hue="blue",
    ).set(
        # å¼·åˆ¶æ·±è‰²æ¨¡å¼èƒŒæ™¯
        background_fill_primary="*neutral_950",
        background_fill_secondary="*neutral_900",
        block_background_fill="*neutral_900",
        # æ–‡å­—é¡è‰²
        body_text_color="*neutral_200",
        body_text_color_subdued="*neutral_400",
        # è¼¸å…¥æ¡†æ¨£å¼
        input_background_fill="*neutral_800",
        input_border_color="*neutral_600",
        # æŒ‰éˆ•æ¨£å¼
        button_primary_background_fill="linear-gradient(135deg, #667eea 0%, #764ba2 100%)",
        button_primary_background_fill_hover="linear-gradient(135deg, #5a6fd8 0%, #694396 100%)",
        button_secondary_background_fill="*neutral_700",
        button_secondary_background_fill_hover="*neutral_600",
    )

    with gr.Blocks(
        title="ResumeMate - AI å±¥æ­·åŠ©æ‰‹",
        css=custom_css,
        theme=dark_theme,
        js="""
        function() {
            // å¼·åˆ¶æ·±è‰²æ¨¡å¼
            document.documentElement.setAttribute('data-theme', 'dark');
            document.body.classList.add('dark');

            // é˜²æ­¢ä¸»é¡Œè‡ªå‹•åˆ‡æ›
            const observer = new MutationObserver(function(mutations) {
                mutations.forEach(function(mutation) {
                    if (mutation.type === 'attributes' &&
                        mutation.attributeName === 'data-theme') {
                        const theme = document.documentElement.getAttribute('data-theme');
                        if (theme !== 'dark') {
                            document.documentElement.setAttribute('data-theme', 'dark');
                            document.body.classList.add('dark');
                        }
                    }
                });
            });

            observer.observe(document.documentElement, {
                attributes: true,
                attributeFilter: ['data-theme']
            });
        }
        """,
    ) as app:
        # æ¨™é¡Œå€åŸŸ
        # title_md = gr.Markdown(TEXTS["title"])
        # description_md = gr.Markdown(TEXTS["description"])

        chatbot = gr.Chatbot(
            label=TEXTS["chat_label"],
            height=400,
            placeholder=TEXTS["chat_placeholder"],
            type="messages",
            allow_tags=False,
        )

        # --- Action Barï¼ˆä¾ action é¡¯ç¤ºï¼‰ ---
        action_md = gr.Markdown(visible=False)

        with gr.Row():
            user_input = gr.Textbox(
                label=TEXTS["input_label"],
                placeholder=TEXTS["input_placeholder"],
                scale=4,
            )
            send_btn = gr.Button(TEXTS["send_button"], variant="primary", scale=1)

        # ç¯„ä¾‹å•é¡Œ
        gr.Examples(
            examples=TEXTS["examples"],
            inputs=user_input,
            label=TEXTS["examples_label"],
        )

        # --- Clarify å€å¡Šï¼ˆéœ€è¦è£œå……è³‡è¨Šæ™‚é¡¯ç¤ºï¼‰ ---
        with gr.Accordion(
            TEXTS["clarify_title"], open=True, visible=False
        ) as clarify_row:
            clarify_input = gr.Textbox(
                label=TEXTS["clarify_label"],
                placeholder=TEXTS["clarify_placeholder"],
            )
            clarify_submit = gr.Button(TEXTS["clarify_submit"])

        # ç³»çµ±ç‹€æ…‹
        with gr.Accordion(TEXTS["status_title"], open=False, visible=False):
            status_display = gr.Markdown(get_system_status())
            refresh_btn = gr.Button(TEXTS["refresh_button"])

        # --- äº‹ä»¶è™•ç†ï¼ˆæ”¯æ´ streamingï¼‰ ---
        async def handle_user_input_with_streaming(user_text, history):
            """è™•ç†ç”¨æˆ¶è¼¸å…¥çš„åŒ…è£å‡½æ•¸ï¼Œæ”¯æ´ streaming"""
            # å…ˆç«‹å³é¡¯ç¤ºç”¨æˆ¶æ¶ˆæ¯ä¸¦éš±è—æ‰€æœ‰ action UIï¼ŒåŒæ™‚ç¦ç”¨æŒ‰éˆ•
            if user_text.strip():
                updated_history = history + [{"role": "user", "content": user_text}]
                # ç¬¬ä¸€æ¬¡ yieldï¼šæ¸…ç©ºè¼¸å…¥æ¡†ã€é¡¯ç¤ºç”¨æˆ¶æ¶ˆæ¯ã€éš±è— action UIã€ç¦ç”¨æŒ‰éˆ•
                yield (
                    "",  # æ¸…ç©ºè¼¸å…¥æ¡†
                    updated_history,  # æ›´æ–°å°è©±æ­·å²
                    gr.update(visible=False),  # action_md
                    gr.update(visible=False),  # clarify_row
                    gr.update(interactive=False, value="è™•ç†ä¸­..."),  # ç¦ç”¨ç™¼é€æŒ‰éˆ•
                )

                # ç„¶å¾Œå•Ÿå‹• streaming è™•ç†ï¼Œå‚³å…¥å®Œæ•´çš„å°è©±æ­·å²ï¼ˆåŒ…å«ç”¨æˆ¶å•é¡Œï¼‰
                last_result = None
                async for result in stream_process_question(user_text, updated_history):
                    last_result = result
                    if len(result) == 3:
                        # streaming éç¨‹ä¸­ä¿æŒæŒ‰éˆ•ç¦ç”¨ç‹€æ…‹
                        yield (
                            "",  # ä¿æŒè¼¸å…¥æ¡†æ¸…ç©º
                            result[0],  # å°è©±æ­·å²
                            result[1],  # action_md
                            result[2],  # clarify_row
                            gr.update(
                                interactive=False, value="è™•ç†ä¸­..."
                            ),  # æŒ‰éˆ•ä»ç¦ç”¨
                        )
                    else:
                        yield (
                            "",
                            result[0],
                            gr.update(visible=False),
                            gr.update(visible=False),
                            gr.update(interactive=False, value="è™•ç†ä¸­..."),
                        )

                # æœ€å¾Œå•Ÿç”¨æŒ‰éˆ•
                if last_result and len(last_result) == 3:
                    yield (
                        "",
                        last_result[0],
                        last_result[1],
                        last_result[2],
                        gr.update(interactive=True, value="ç™¼é€"),  # æ¢å¾©æŒ‰éˆ•
                    )
                elif last_result:
                    yield (
                        "",
                        last_result[0],
                        gr.update(visible=False),
                        gr.update(visible=False),
                        gr.update(visible=False),
                        gr.update(interactive=True, value="ç™¼é€"),
                    )
            else:
                # ç©ºè¼¸å…¥çš„æƒ…æ³
                async for result in stream_process_question(user_text, history):
                    if len(result) == 3:
                        yield (
                            "",
                            result[0],
                            result[1],
                            result[2],
                            gr.update(interactive=True, value="ç™¼é€"),
                        )
                    else:
                        yield (
                            "",
                            result[0],
                            gr.update(visible=False),
                            gr.update(visible=False),
                            gr.update(interactive=True, value="ç™¼é€"),
                        )

        send_btn.click(
            fn=handle_user_input_with_streaming,
            inputs=[user_input, chatbot],
            outputs=[
                user_input,
                chatbot,
                action_md,
                clarify_row,
                send_btn,
            ],
        )
        user_input.submit(
            fn=handle_user_input_with_streaming,
            inputs=[user_input, chatbot],
            outputs=[
                user_input,
                chatbot,
                action_md,
                clarify_row,
                send_btn,
            ],
        )

        async def handle_clarify_with_streaming(clarify_text, history):
            """è™•ç†è£œå……è³‡è¨Šçš„åŒ…è£å‡½æ•¸"""
            # å…ˆç«‹å³é¡¯ç¤ºç”¨æˆ¶è£œå……çš„æ¶ˆæ¯ä¸¦éš±è—æ‰€æœ‰ action UIï¼ŒåŒæ™‚ç¦ç”¨æŒ‰éˆ•
            if clarify_text.strip():
                updated_history = history + [{"role": "user", "content": clarify_text}]
                # ç¬¬ä¸€æ¬¡ yieldï¼šæ¸…ç©ºè¼¸å…¥æ¡†ã€é¡¯ç¤ºç”¨æˆ¶æ¶ˆæ¯ã€éš±è— action UIã€ç¦ç”¨æŒ‰éˆ•
                yield (
                    "",  # æ¸…ç©º clarify_input
                    updated_history,  # æ›´æ–°å°è©±æ­·å²
                    gr.update(visible=False),  # action_md
                    gr.update(visible=False),  # clarify_row
                    gr.update(
                        interactive=False, value="è™•ç†ä¸­..."
                    ),  # ç¦ç”¨ clarify æŒ‰éˆ•
                )

                # ç„¶å¾Œå•Ÿå‹• streaming è™•ç†ï¼Œå‚³å…¥å®Œæ•´çš„å°è©±æ­·å²ï¼ˆåŒ…å«è£œå……è³‡è¨Šï¼‰
                last_result = None
                async for result in stream_process_question(
                    clarify_text, updated_history
                ):
                    last_result = result
                    if len(result) == 3:
                        # streaming éç¨‹ä¸­ä¿æŒæŒ‰éˆ•ç¦ç”¨ç‹€æ…‹
                        yield (
                            "",  # ä¿æŒè¼¸å…¥æ¡†æ¸…ç©º
                            result[0],  # å°è©±æ­·å²
                            result[1],  # action_md
                            result[2],  # clarify_row
                            gr.update(
                                interactive=False, value="è™•ç†ä¸­..."
                            ),  # æŒ‰éˆ•ä»ç¦ç”¨
                        )
                    else:
                        yield (
                            "",
                            result[0],
                            gr.update(visible=False),
                            gr.update(visible=False),
                            gr.update(interactive=False, value="è™•ç†ä¸­..."),
                        )

                # æœ€å¾Œå•Ÿç”¨æŒ‰éˆ•
                if last_result and len(last_result) == 3:
                    yield (
                        "",
                        last_result[0],
                        last_result[1],
                        last_result[2],
                        gr.update(
                            interactive=True, value="é€å‡ºè£œå……"
                        ),  # æ¢å¾© clarify æŒ‰éˆ•
                    )
                elif last_result:
                    yield (
                        "",
                        last_result[0],
                        gr.update(visible=False),
                        gr.update(visible=False),
                        gr.update(visible=False),
                        gr.update(interactive=True, value="é€å‡ºè£œå……"),
                    )
            else:
                # ç©ºè¼¸å…¥çš„æƒ…æ³
                async for result in stream_process_question(clarify_text, history):
                    if len(result) == 3:
                        yield (
                            "",
                            result[0],
                            result[1],
                            result[2],
                            gr.update(interactive=True, value="é€å‡ºè£œå……"),
                        )
                    else:
                        yield (
                            "",
                            result[0],
                            gr.update(visible=False),
                            gr.update(visible=False),
                            gr.update(interactive=True, value="é€å‡ºè£œå……"),
                        )

        clarify_submit.click(
            fn=handle_clarify_with_streaming,
            inputs=[clarify_input, chatbot],
            outputs=[
                clarify_input,
                chatbot,
                action_md,
                clarify_row,
                clarify_submit,
            ],
        )

        refresh_btn.click(fn=get_system_status, outputs=status_display)

    return app


def main():
    """ä¸»å‡½æ•¸"""
    logger.info("å•Ÿå‹• ResumeMate Gradio æ‡‰ç”¨ç¨‹å¼")

    app = create_gradio_interface()

    server_name = os.getenv("GRADIO_SERVER_NAME", "0.0.0.0")
    try:
        server_port = int(os.getenv("GRADIO_SERVER_PORT", "7860"))
    except ValueError:
        server_port = 7860

    # ç¢ºå®šæ˜¯å¦ä½¿ç”¨å…±äº«æ¨¡å¼
    use_share = os.getenv("GRADIO_SHARE", "").lower() in ("true", "1", "yes")

    model = os.getenv("LITELLM_PROXY_MODEL", "github_copilot/gpt-4o")
    logger.info(f"ä½¿ç”¨çš„ä»£ç†æ¨¡å‹: {model}")

    # å•Ÿå‹•æ‡‰ç”¨ç¨‹å¼
    if use_share:
        # ä½¿ç”¨ Gradio çš„å…±äº«é€£çµï¼ˆå…è¨±å¤–éƒ¨è¨ªå•ï¼‰
        logger.info("ä½¿ç”¨ Gradio å…±äº«æ¨¡å¼ï¼Œç”Ÿæˆå…¬é–‹é€£çµ...")
        app.launch(
            server_name=server_name,
            server_port=server_port,
            share=True,
            debug=True,
            quiet=False,
        )
    else:
        # å˜—è©¦åœ¨æŒ‡å®šåŸ å•Ÿå‹•ï¼Œå¦‚æœå¤±æ•—å‰‡è®“ Gradio è‡ªå‹•æ‰¾å¯ç”¨åŸ 
        max_port_attempts = 10
        for port_offset in range(max_port_attempts):
            try_port = server_port + port_offset
            try:
                logger.info(f"åœ¨æ‰€æœ‰ç¶²çµ¡ä»‹é¢å•Ÿå‹•æ‡‰ç”¨ ({server_name}:{try_port})...")
                app.launch(
                    server_name=server_name,
                    server_port=try_port,
                    share=False,
                    debug=True,
                    quiet=False,
                )
                break  # æˆåŠŸå•Ÿå‹•ï¼Œè·³å‡ºè¿´åœˆ
            except OSError:
                if port_offset < max_port_attempts - 1:
                    logger.warning(f"åŸ  {try_port} è¢«ä½”ç”¨ï¼Œå˜—è©¦ä¸‹ä¸€å€‹åŸ ...")
                else:
                    # æ‰€æœ‰åŸ éƒ½å¤±æ•—ï¼Œå•Ÿç”¨å…±äº«æ¨¡å¼
                    logger.warning("ç„¡æ³•æ‰¾åˆ°å¯ç”¨åŸ ï¼Œå•Ÿç”¨å…±äº«é€£çµ...")
                    app.launch(
                        server_name=server_name,
                        share=True,
                        debug=True,
                        quiet=False,
                    )


if __name__ == "__main__":
    main()
